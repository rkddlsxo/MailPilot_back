from flask import Flask, request, jsonify, session
from email.header import decode_header
from email.utils import parseaddr, parsedate_to_datetime
from flask_cors import CORS
from datetime import datetime
import imaplib
import smtplib
import traceback
from email.mime.text import MIMEText
from transformers import pipeline
from nomic import embed
from sklearn.metrics.pairwise import cosine_similarity
from nomic import login
import os
import hashlib
import uuid
from huggingface_hub import InferenceClient
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from pprint import pprint
import re
import email as email_module
import email

# âœ… YOLOv8 ê´€ë ¨ import ì¶”ê°€
import cv2
import numpy as np
from pathlib import Path
import base64
from PIL import Image
import io

# ë³´ê³ ì„œ íŒŒì¼ ì²˜ë¦¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import pdfplumber  # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
import PyPDF2     # PDF ë°±ì—… ì²˜ë¦¬
from docx import Document  # Word ë¬¸ì„œ ì²˜ë¦¬  
from pptx import Presentation  # PowerPoint ì²˜ë¦¬
import pandas as pd  # Excel ì²˜ë¦¬
import easyocr  # OCR ì²˜ë¦¬
from pdf2image import convert_from_bytes  # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
import mimetypes  # MIME íƒ€ì… ê°ì§€
from pathlib import Path
import tempfile


# to ëŒ€ì‰¬ë³´ë“œìš© ì¶”ê°€í•  ì½”ë“œ

import dateutil.parser
from datetime import datetime, timedelta
import re
import json
import time

from pathlib import Path  # ì´ ì¤„ì„ ê¸°ì¡´ importë“¤ê³¼ í•¨ê»˜ ì¶”ê°€

# YOLOv8 ì„¤ì¹˜ í™•ì¸ ë° ë¡œë”©
from ultralytics import YOLO
print("[âœ… YOLOv8 ì‚¬ìš© ê°€ëŠ¥]")

login(token="í† í°")

# Hugging Face í† í° ì„¤ì •
os.environ['HF_TOKEN'] = 'í† ê·¼'

candidate_labels = [
    "university.",
    "spam mail.",
    "company.",
    "security alert."
]

app = Flask(__name__)
CORS(app, supports_credentials=True)  # ì„¸ì…˜ ì¿ í‚¤ ì§€ì›
app.secret_key = 'your-secret-key-here'  # ì„¸ì…˜ ì•”í˜¸í™”ìš© í‚¤

# âœ… Qwen ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ (í•œ ë²ˆë§Œ ë¡œë”©í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)
qwen_model = None
qwen_tokenizer = None

# âœ… YOLO ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ ì¶”ê°€
yolo_model = None

# OCR ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
ocr_reader = None

# ì‚¬ìš©ìë³„ ë°ì´í„° ì €ì¥ì†Œ (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” Redisë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ê¶Œì¥)
user_sessions = {}

# ====================================
# app.pyì— ì¶”ê°€í•  ì½”ë“œ (user_sessions = {} ë°”ë¡œ ì•„ë˜)
# ====================================

# íŒŒì¼ ê¸°ë°˜ ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±
USER_DATA_DIR = Path("user_sessions")
USER_DATA_DIR.mkdir(exist_ok=True)
print(f"[ğŸ“ ë°ì´í„° ì €ì¥ì†Œ] ìƒì„±: {USER_DATA_DIR}")

def get_user_file_path(user_email):
    """ì‚¬ìš©ìë³„ ë°ì´í„° íŒŒì¼ ê²½ë¡œ"""
    user_hash = hashlib.md5(user_email.encode()).hexdigest()[:16]
    return USER_DATA_DIR / f"user_{user_hash}.json"

def save_user_session_to_file(user_email):
    """í˜„ì¬ ì„¸ì…˜ì„ íŒŒì¼ì— ì €ì¥"""
    try:
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return False
            
        file_path = get_user_file_path(user_email)
        session_data = user_sessions[user_key]
        
        save_data = {
            'user_email': user_email,
            'extracted_todos': session_data.get('extracted_todos', []),
            'last_emails': session_data.get('last_emails', []),
            'last_update': datetime.now().isoformat(),
            'login_time': session_data.get('login_time'),
            'session_id': session_data.get('session_id')
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        todos_count = len(session_data.get('extracted_todos', []))
        print(f"[ğŸ’¾ ì„¸ì…˜ ì €ì¥] {user_email}: {todos_count}ê°œ í• ì¼")
        return True
        
    except Exception as e:
        print(f"[â—ì €ì¥ ì‹¤íŒ¨] {user_email}: {str(e)}")
        return False

def load_user_session_from_file(user_email):
    """íŒŒì¼ì—ì„œ ì„¸ì…˜ ë°ì´í„° ë¡œë“œ"""
    try:
        file_path = get_user_file_path(user_email)
        
        if not file_path.exists():
            print(f"[ğŸ“ ìƒˆ ì‚¬ìš©ì] {user_email}")
            return None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if data.get('user_email') == user_email:
            todos_count = len(data.get('extracted_todos', []))
            print(f"[ğŸ“‚ ì„¸ì…˜ ë³µì›] {user_email}: {todos_count}ê°œ í• ì¼")
            return data
            
        return None
        
    except Exception as e:
        print(f"[â—ë¡œë“œ ì‹¤íŒ¨] {user_email}: {str(e)}")
        return None

# ====================================
# ê¸°ì¡´ í•¨ìˆ˜ë“¤ ìˆ˜ì •
# ====================================

# ê¸°ì¡´ clear_user_session í•¨ìˆ˜ë¥¼ ì´ê²ƒìœ¼ë¡œ êµì²´
def clear_user_session(email):
    """íŠ¹ì • ì‚¬ìš©ìì˜ ì„¸ì…˜ ìˆ˜ì • - íŒŒì¼ì€ ìœ ì§€"""
    user_key = get_user_key(email)
    if user_key in user_sessions:
        # íŒŒì¼ì— ì €ì¥ í›„ ë©”ëª¨ë¦¬ì—ì„œë§Œ ì‚­ì œ
        save_user_session_to_file(email)
        del user_sessions[user_key]
        print(f"[ğŸ—‘ï¸ ì„¸ì…˜ ì •ë¦¬] {email} - íŒŒì¼ ì €ì¥ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬")

# ê¸°ì¡´ login_user í•¨ìˆ˜ë¥¼ ì´ê²ƒìœ¼ë¡œ êµì²´
@app.route('/api/login', methods=['POST'])
def login_user():
    """ê°œì„ ëœ ë¡œê·¸ì¸ - íŒŒì¼ì—ì„œ ë°ì´í„° ë³µì›"""
    try:
        data = request.get_json()
        email = data.get('email', '')
        
        if email:
            # ì´ì „ ì„¸ì…˜ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ (íŒŒì¼ì€ ìœ ì§€)
            clear_user_session(email)
            
            # íŒŒì¼ì—ì„œ ì„¸ì…˜ ë³µì› ì‹œë„
            saved_data = load_user_session_from_file(email)
            
            # ìƒˆ ì„¸ì…˜ ìƒì„±
            session_id = get_session_id()
            user_key = get_user_key(email)
            
            if saved_data:
                # íŒŒì¼ì—ì„œ ë³µì›
                user_sessions[user_key] = {
                    'email': email,
                    'session_id': session_id,
                    'extracted_todos': saved_data.get('extracted_todos', []),
                    'last_emails': saved_data.get('last_emails', []),
                    'login_time': datetime.now().isoformat()
                }
                
                todos_count = len(saved_data.get('extracted_todos', []))
                print(f"[ğŸ”‘ ë¡œê·¸ì¸ + ë³µì›] {email}: {todos_count}ê°œ í• ì¼ ë³µì›")
                
                return jsonify({
                    'success': True,
                    'message': f'ë¡œê·¸ì¸ ì„±ê³µ - {todos_count}ê°œ í• ì¼ ë³µì›ë¨',
                    'session_id': session_id,
                    'restored_todos': todos_count
                })
            else:
                # ìƒˆ ì„¸ì…˜ ìƒì„±
                user_sessions[user_key] = {
                    'email': email,
                    'session_id': session_id,
                    'last_emails': [],
                    'extracted_todos': [],
                    'login_time': datetime.now().isoformat()
                }
                
                print(f"[ğŸ”‘ ìƒˆ ë¡œê·¸ì¸] {email}")
                
                return jsonify({
                    'success': True,
                    'message': 'ë¡œê·¸ì¸ ì„±ê³µ - ìƒˆ ì„¸ì…˜',
                    'session_id': session_id,
                    'restored_todos': 0
                })
        else:
            return jsonify({'error': 'ì´ë©”ì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
            
    except Exception as e:
        print(f"[â—ë¡œê·¸ì¸ ì‹¤íŒ¨] {str(e)}")
        return jsonify({'error': str(e)}), 500

# ê¸°ì¡´ todos_api_improved í•¨ìˆ˜ì— ìë™ ì €ì¥ ì¶”ê°€
@app.route('/api/todos', methods=['GET', 'POST', 'PUT', 'DELETE'])
def todos_api_improved():
    """í• ì¼ API - ìë™ íŒŒì¼ ì €ì¥ ì¶”ê°€"""
    try:
        if request.method == 'GET':
            user_email = request.args.get('email')
        else:
            user_email = request.json.get('email') if request.json else None
            
        if not user_email:
            return jsonify({"error": "ì´ë©”ì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        if request.method == 'GET':
            todos = user_sessions[user_key].get('extracted_todos', [])
            return jsonify({
                "success": True,
                "todos": todos,
                "total_count": len(todos)
            })
        
        elif request.method == 'POST':
            # ìƒˆ í• ì¼ ì¶”ê°€
            data = request.json
            
            existing_todos = user_sessions[user_key].get('extracted_todos', [])
            max_id = max([todo.get('id', 0) for todo in existing_todos] + [0])
            new_id = max_id + 1
            
            new_todo = {
                'id': new_id,
                'type': data.get('type', 'task'),
                'title': data.get('title', ''),
                'description': data.get('description', ''),
                'date': data.get('date'),
                'time': data.get('time'),
                'priority': data.get('priority', 'medium'),
                'status': 'pending',
                'editable_date': True,
                'source_email': {
                    'from': 'manual',
                    'subject': 'Manual Entry',
                    'date': datetime.now().isoformat(),
                    'type': 'manual_entry'
                }
            }
            
            existing_todos.append(new_todo)
            user_sessions[user_key]['extracted_todos'] = existing_todos
            
            # íŒŒì¼ì— ìë™ ì €ì¥
            save_user_session_to_file(user_email)
            
            print(f"[âœ… í• ì¼ ì¶”ê°€ + ì €ì¥] ID: {new_id}")
            
            return jsonify({
                "success": True,
                "todo": new_todo,
                "message": "í• ì¼ì´ ì¶”ê°€ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
            })
        
        elif request.method == 'PUT':
            # í• ì¼ ì—…ë°ì´íŠ¸
            data = request.json
            todo_id = data.get('id')
            
            todos = user_sessions[user_key].get('extracted_todos', [])
            updated = False
            
            for todo in todos:
                if todo.get('id') == todo_id:
                    if 'status' in data:
                        todo['status'] = data['status']
                    if 'date' in data and todo.get('editable_date', True):
                        todo['date'] = data['date']
                    if 'time' in data and todo.get('editable_date', True):
                        todo['time'] = data['time']
                    
                    updated = True
                    break
            
            if updated:
                user_sessions[user_key]['extracted_todos'] = todos
                
                # íŒŒì¼ì— ìë™ ì €ì¥
                save_user_session_to_file(user_email)
                
                print(f"[âœ… í• ì¼ ì—…ë°ì´íŠ¸ + ì €ì¥] ID: {todo_id}")
                
                return jsonify({
                    "success": True,
                    "message": "í• ì¼ì´ ì—…ë°ì´íŠ¸ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
                })
            else:
                return jsonify({"error": "í•´ë‹¹ í• ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        elif request.method == 'DELETE':
            # í• ì¼ ì‚­ì œ
            data = request.json
            todo_id = data.get('id')
            
            todos = user_sessions[user_key].get('extracted_todos', [])
            original_count = len(todos)
            
            todos = [todo for todo in todos if todo.get('id') != todo_id]
            
            if len(todos) < original_count:
                user_sessions[user_key]['extracted_todos'] = todos
                
                # íŒŒì¼ì— ìë™ ì €ì¥
                save_user_session_to_file(user_email)
                
                print(f"[âœ… í• ì¼ ì‚­ì œ + ì €ì¥] ID: {todo_id}")
                
                return jsonify({
                    "success": True,
                    "message": "í• ì¼ì´ ì‚­ì œë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
                })
            else:
                return jsonify({"error": "í•´ë‹¹ í• ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
    except Exception as e:
        print(f"[â—í• ì¼ API ì˜¤ë¥˜] {str(e)}")
        return jsonify({"error": str(e)}), 500

# ê¸°ì¡´ extract_todos_api í•¨ìˆ˜ì— ìë™ ì €ì¥ ì¶”ê°€
@app.route('/api/extract-todos', methods=['POST'])
def extract_todos_api():
    """í• ì¼ ì¶”ì¶œ API - ìë™ íŒŒì¼ ì €ì¥ ì¶”ê°€"""
    try:
        data = request.get_json()
        user_email = data.get("email", "")
        app_password = data.get("app_password", "")
        email_ids = data.get("email_ids", [])
        
        print(f"[ğŸ“‹ í• ì¼ ì¶”ì¶œ] ì‚¬ìš©ì: {user_email}")
        
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        last_emails = user_sessions[user_key].get('last_emails', [])
        
        all_todos = []
        processed_count = 0
        
        emails_to_process = last_emails
        if email_ids:
            emails_to_process = [email for email in last_emails if email.get('id') in email_ids]
        
        for email_data in emails_to_process:
            try:
                result = extract_todos_from_email_improved(
                    email_body=email_data.get('body', ''),
                    email_subject=email_data.get('subject', ''),
                    email_from=email_data.get('from', ''),
                    email_date=email_data.get('date', '')
                )
                
                if result['success']:
                    for todo in result['todos']:
                        todo['source_email']['id'] = email_data.get('id')
                        todo['source_email']['subject'] = email_data.get('subject', '')
                    
                    all_todos.extend(result['todos'])
                    processed_count += 1
                    
            except Exception as e:
                continue
        
        # ê¸°ì¡´ í• ì¼ê³¼ ë³‘í•©
        existing_todos = user_sessions[user_key].get('extracted_todos', [])
        existing_ids = {todo.get('id') for todo in existing_todos}
        
        new_todos = [todo for todo in all_todos if todo.get('id') not in existing_ids]
        final_todos = existing_todos + new_todos
        
        final_todos.sort(key=lambda x: x['date'] or '9999-12-31')
        
        user_sessions[user_key]['extracted_todos'] = final_todos
        
        # íŒŒì¼ì— ìë™ ì €ì¥
        save_user_session_to_file(user_email)
        
        print(f"[âœ… í• ì¼ ì¶”ì¶œ + ì €ì¥] ì´ {len(final_todos)}ê°œ (ì‹ ê·œ {len(new_todos)}ê°œ)")
        
        return jsonify({
            "success": True,
            "todos": final_todos,
            "total_count": len(final_todos),
            "new_todos": len(new_todos),
            "processed_emails": processed_count
        })
        
    except Exception as e:
        print(f"[â—í• ì¼ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
        return jsonify({"error": str(e)}), 500

# âœ… ì´ ì¤„ì„ ì¶”ê°€í•˜ì„¸ìš”
attachment_cache = {}  # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ê²°ê³¼ ìºì‹œ

# âœ… ì²¨ë¶€íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
ATTACHMENT_FOLDER = "static/attachments"
os.makedirs(ATTACHMENT_FOLDER, exist_ok=True)

# ===== YOLOv8 ê´€ë ¨ í•¨ìˆ˜ë“¤ ì¶”ê°€ =====
def load_yolo_model():
    """YOLO ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    global yolo_model

    if yolo_model is None:
        try:
            print("[ğŸ¤– YOLOv8 ëª¨ë¸ ë¡œë”© ì‹œì‘]")
            yolo_model = YOLO('yolov8n.pt')  # ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©
            print("[âœ… YOLOv8 ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
            return True
        except Exception as e:
            print(f"[â—YOLO ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
            return False
    return True
def process_image_with_yolo(image_data, confidence_threshold=0.2):
    """ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ YOLOë¡œ ì²˜ë¦¬ (PNG RGBA ë¬¸ì œ í•´ê²°)"""
    global yolo_model
    
    if not load_yolo_model():
        return []
    
    try:
        # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(image_data))
        
        # âœ… PNG RGBA â†’ RGB ë³€í™˜ (í•µì‹¬ ìˆ˜ì •)
        if image.mode == 'RGBA' or image.mode == 'LA':
            print(f"[ğŸ”„ ì´ë¯¸ì§€ ë³€í™˜] {image.mode} â†’ RGB")
            # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ RGBA â†’ RGB ë³€í™˜
            rgb_image = Image.new('RGB', image.size, (255, 255, 255))
            rgb_image.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
            image = rgb_image
        elif image.mode != 'RGB':
            print(f"[ğŸ”„ ì´ë¯¸ì§€ ë³€í™˜] {image.mode} â†’ RGB")
            image = image.convert('RGB')
        
        image_np = np.array(image)
        print(f"[ğŸ“ ì´ë¯¸ì§€ í¬ê¸°] {image_np.shape}")  # ë””ë²„ê·¸ìš©
        
        # YOLO ì¶”ë¡ 
        results = yolo_model(image_np, conf=confidence_threshold)
        
        detections = []
        if len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes
            for i in range(len(boxes)):
                conf = float(boxes.conf[i].cpu().numpy())
                cls = int(boxes.cls[i].cpu().numpy())
                class_name = yolo_model.names[cls]
                
                detections.append({
                    'class': class_name,
                    'confidence': conf,
                    'class_id': cls
                })
                
                print(f"  - {class_name}: {conf:.2f}")  # ë””ë²„ê·¸ìš©
        
        return detections
        
    except Exception as e:
        print(f"[â—YOLO ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜] {str(e)}")
        return []

def load_ocr_model():
    """EasyOCR ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    global ocr_reader
    
    if ocr_reader is None:
        try:
            print("[ğŸ“– EasyOCR ëª¨ë¸ ë¡œë”© ì‹œì‘]")
            ocr_reader = easyocr.Reader(['ko', 'en'])  # í•œêµ­ì–´, ì˜ì–´ ì§€ì›
            print("[âœ… EasyOCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
            return True
        except Exception as e:
            print(f"[â—EasyOCR ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
            return False
    return True

def extract_text_from_pdf(attachment_data):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR ë°±ì—… í¬í•¨)"""
    try:
        # 1ë‹¨ê³„: pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        print("[ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„]")
        
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
            temp_file.write(attachment_data)
            temp_file_path = temp_file.name
        
        try:
            with pdfplumber.open(temp_file_path) as pdf:
                text = ""
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== í˜ì´ì§€ {page_num + 1} ===\n{page_text}\n"
                
                if text.strip():
                    print(f"[âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ] {len(text)}ì")
                    return {
                        'text': text.strip(),
                        'method': 'direct_extraction',
                        'pages': len(pdf.pages),
                        'success': True
                    }
        except Exception as e:
            print(f"[âš ï¸ pdfplumber ì‹¤íŒ¨] {str(e)}")
        
        # 2ë‹¨ê³„: PyPDF2ë¡œ ì¬ì‹œë„
        try:
            with open(temp_file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page_num, page in enumerate(pdf_reader.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== í˜ì´ì§€ {page_num + 1} ===\n{page_text}\n"
                
                if text.strip():
                    print(f"[âœ… PyPDF2 í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ] {len(text)}ì")
                    return {
                        'text': text.strip(),
                        'method': 'pypdf2_extraction',
                        'pages': len(pdf_reader.pages),
                        'success': True
                    }
        except Exception as e:
            print(f"[âš ï¸ PyPDF2 ì‹¤íŒ¨] {str(e)}")
        
        # 3ë‹¨ê³„: OCR ë°±ì—… ì²˜ë¦¬
        print("[ğŸ” PDF OCR ë°±ì—… ì²˜ë¦¬ ì‹œì‘]")
        return extract_text_from_pdf_ocr(attachment_data)
        
    except Exception as e:
        print(f"[â—PDF ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'failed',
            'error': str(e),
            'success': False
        }
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            os.unlink(temp_file_path)
        except:
            pass

def extract_text_from_pdf_ocr(attachment_data):
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCR ì²˜ë¦¬"""
    try:
        if not load_ocr_model():
            return {'text': '', 'method': 'ocr_failed', 'success': False}
        
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_bytes(attachment_data, dpi=200)
        
        all_text = ""
        for page_num, image in enumerate(images):
            # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
            image_np = np.array(image)
            
            # OCR ìˆ˜í–‰
            result = ocr_reader.readtext(image_np, paragraph=True)
            
            page_text = ""
            for detection in result:
                text = detection[1]
                confidence = detection[2]
                if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ
                    page_text += text + " "
            
            if page_text.strip():
                all_text += f"\n=== í˜ì´ì§€ {page_num + 1} (OCR) ===\n{page_text.strip()}\n"
        
        if all_text.strip():
            print(f"[âœ… PDF OCR ì„±ê³µ] {len(all_text)}ì")
            return {
                'text': all_text.strip(),
                'method': 'ocr_extraction',
                'pages': len(images),
                'success': True
            }
        else:
            return {
                'text': '',
                'method': 'ocr_no_text',
                'success': False
            }
            
    except Exception as e:
        print(f"[â—PDF OCR ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'ocr_failed',
            'error': str(e),
            'success': False
        }

def extract_text_from_docx(attachment_data):
    """Word ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        print("[ğŸ“ DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„]")
        
        with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_file:
            temp_file.write(attachment_data)
            temp_file_path = temp_file.name
        
        try:
            doc = Document(temp_file_path)
            
            text = ""
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text += paragraph.text + "\n"
            
            # í‘œ(Table) ë‚´ìš©ë„ ì¶”ì¶œ
            for table in doc.tables:
                text += "\n=== í‘œ ë°ì´í„° ===\n"
                for row in table.rows:
                    row_text = []
                    for cell in row.cells:
                        if cell.text.strip():
                            row_text.append(cell.text.strip())
                    if row_text:
                        text += " | ".join(row_text) + "\n"
            
            if text.strip():
                print(f"[âœ… DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ] {len(text)}ì")
                return {
                    'text': text.strip(),
                    'method': 'docx_extraction',
                    'paragraphs': len(doc.paragraphs),
                    'tables': len(doc.tables),
                    'success': True
                }
            else:
                return {
                    'text': '',
                    'method': 'docx_no_text',
                    'success': False
                }
                
        except Exception as e:
            print(f"[â—DOCX ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
            return {
                'text': '',
                'method': 'docx_failed',
                'error': str(e),
                'success': False
            }
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
                
    except Exception as e:
        print(f"[â—DOCX íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'docx_failed',
            'error': str(e),
            'success': False
        }

def extract_text_from_pptx(attachment_data):
    """PowerPoint íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        print("[ğŸ“Š PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„]")
        
        with tempfile.NamedTemporaryFile(suffix='.pptx', delete=False) as temp_file:
            temp_file.write(attachment_data)
            temp_file_path = temp_file.name
        
        try:
            prs = Presentation(temp_file_path)
            
            text = ""
            for slide_num, slide in enumerate(prs.slides):
                text += f"\n=== ìŠ¬ë¼ì´ë“œ {slide_num + 1} ===\n"
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        text += shape.text + "\n"
                    
                    # í‘œê°€ ìˆëŠ” ê²½ìš°
                    if shape.has_table:
                        text += "\n--- í‘œ ---\n"
                        table = shape.table
                        for row in table.rows:
                            row_text = []
                            for cell in row.cells:
                                if cell.text.strip():
                                    row_text.append(cell.text.strip())
                            if row_text:
                                text += " | ".join(row_text) + "\n"
            
            if text.strip():
                print(f"[âœ… PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ] {len(text)}ì, {len(prs.slides)}ê°œ ìŠ¬ë¼ì´ë“œ")
                return {
                    'text': text.strip(),
                    'method': 'pptx_extraction',
                    'slides': len(prs.slides),
                    'success': True
                }
            else:
                return {
                    'text': '',
                    'method': 'pptx_no_text',
                    'success': False
                }
                
        except Exception as e:
            print(f"[â—PPTX ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
            return {
                'text': '',
                'method': 'pptx_failed',
                'error': str(e),
                'success': False
            }
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
                
    except Exception as e:
        print(f"[â—PPTX íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'pptx_failed',
            'error': str(e),
            'success': False
        }

def extract_text_from_xlsx(attachment_data):
    """Excel íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    try:
        print("[ğŸ“Š XLSX ë°ì´í„° ì¶”ì¶œ ì‹œë„]")
        
        with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as temp_file:
            temp_file.write(attachment_data)
            temp_file_path = temp_file.name
        
        try:
            # ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
            xl_file = pd.ExcelFile(temp_file_path)
            
            text = ""
            total_rows = 0
            
            for sheet_name in xl_file.sheet_names:
                df = pd.read_excel(temp_file_path, sheet_name=sheet_name)
                
                if not df.empty:
                    text += f"\n=== ì‹œíŠ¸: {sheet_name} ===\n"
                    
                    # ì»¬ëŸ¼ëª… ì¶”ê°€
                    text += "ì»¬ëŸ¼: " + " | ".join(str(col) for col in df.columns) + "\n\n"
                    
                    # ë°ì´í„° ì¶”ê°€ (ì²˜ìŒ 20í–‰ë§Œ)
                    for idx, row in df.head(20).iterrows():
                        row_text = []
                        for value in row:
                            if pd.notna(value):
                                row_text.append(str(value))
                            else:
                                row_text.append("")
                        text += " | ".join(row_text) + "\n"
                    
                    total_rows += len(df)
                    
                    if len(df) > 20:
                        text += f"... (ì´ {len(df)}í–‰ ì¤‘ ì²˜ìŒ 20í–‰ë§Œ í‘œì‹œ)\n"
            
            if text.strip():
                print(f"[âœ… XLSX ë°ì´í„° ì¶”ì¶œ ì„±ê³µ] {len(text)}ì, {total_rows}í–‰")
                return {
                    'text': text.strip(),
                    'method': 'xlsx_extraction',
                    'sheets': len(xl_file.sheet_names),
                    'total_rows': total_rows,
                    'success': True
                }
            else:
                return {
                    'text': '',
                    'method': 'xlsx_no_data',
                    'success': False
                }
                
        except Exception as e:
            print(f"[â—XLSX ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
            return {
                'text': '',
                'method': 'xlsx_failed',
                'error': str(e),
                'success': False
            }
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
                
    except Exception as e:
        print(f"[â—XLSX íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'xlsx_failed',
            'error': str(e),
            'success': False
        }
def extract_text_with_ocr(attachment_data, filename):
    """ì¼ë°˜ ì´ë¯¸ì§€ íŒŒì¼ OCR ì²˜ë¦¬ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)"""
    try:
        if not load_ocr_model():
            return {'text': '', 'method': 'ocr_model_failed', 'success': False}
        
        print(f"[ğŸ” ì´ë¯¸ì§€ OCR ì²˜ë¦¬] {filename}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        image = Image.open(io.BytesIO(attachment_data))
        
        # âœ… PNG RGBA â†’ RGB ë³€í™˜ (YOLOì™€ ë™ì¼)
        if image.mode == 'RGBA' or image.mode == 'LA':
            print(f"[ğŸ”„ OCR ì´ë¯¸ì§€ ë³€í™˜] {image.mode} â†’ RGB")
            rgb_image = Image.new('RGB', image.size, (255, 255, 255))
            rgb_image.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
            image = rgb_image
        elif image.mode != 'RGB':
            print(f"[ğŸ”„ OCR ì´ë¯¸ì§€ ë³€í™˜] {image.mode} â†’ RGB")
            image = image.convert('RGB')
        
        image_np = np.array(image)
        
        # OCR ìˆ˜í–‰
        result = ocr_reader.readtext(image_np, paragraph=True)
        
        # âœ… OCR ê²°ê³¼ ì•ˆì „ ì²˜ë¦¬
        text = ""
        if result and len(result) > 0:
            for detection in result:
                try:
                    # EasyOCR ê²°ê³¼ êµ¬ì¡°: [bbox, text, confidence]
                    if len(detection) >= 3:
                        text_content = detection[1]
                        confidence = detection[2]
                        if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ
                            text += text_content + " "
                except Exception as detail_error:
                    print(f"[âš ï¸ OCR ê°œë³„ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜] {str(detail_error)}")
                    continue
        
        if text.strip():
            print(f"[âœ… ì´ë¯¸ì§€ OCR ì„±ê³µ] {len(text)}ì")
            return {
                'text': text.strip(),
                'method': 'image_ocr',
                'success': True
            }
        else:
            print(f"[ğŸ“ OCR í…ìŠ¤íŠ¸ ì—†ìŒ] {filename}")
            return {
                'text': '',
                'method': 'ocr_no_text',
                'success': False
            }
            
    except Exception as e:
        print(f"[â—ì´ë¯¸ì§€ OCR ì‹¤íŒ¨] {str(e)}")
        return {
            'text': '',
            'method': 'ocr_failed',
            'error': str(e),
            'success': False
        }
    
def summarize_document_with_llm(text, filename, file_type):
    """LLMì„ ì´ìš©í•œ ë¬¸ì„œ ìš”ì•½"""
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (4000ì ì œí•œ)
        if len(text) > 4000:
            text = text[:4000] + "..."
        
        # Hugging Face í† í° í™•ì¸
        hf_token = os.getenv("HF_TOKEN")
        if not hf_token:
            print("[âš ï¸ HF_TOKEN ì—†ìŒ - ê°„ë‹¨ ìš”ì•½ ì‚¬ìš©]")
            return text[:300] + "..." if len(text) > 300 else text
        
        try:
            client = InferenceClient(
                model="Qwen/Qwen2.5-7B-Instruct",
                token=hf_token
            )
            
            prompt = f"""ë‹¤ìŒì€ '{filename}' íŒŒì¼ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.

íŒŒì¼ í˜•ì‹: {file_type}
ë‚´ìš©:
{text}

ìš”ì•½ ì§€ì¹¨:
1. ì£¼ìš” ë‚´ìš©ì„ 3-5ê°œ í¬ì¸íŠ¸ë¡œ ìš”ì•½
2. í•µì‹¬ í‚¤ì›Œë“œì™€ ìˆ˜ì¹˜ í¬í•¨
3. 150ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
4. í•œêµ­ì–´ë¡œ ì‘ë‹µ

ìš”ì•½:"""
            
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = client.chat_completion(
                messages=messages,
                max_tokens=200,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            
            print(f"[âœ… LLM ìš”ì•½ ì™„ë£Œ] {filename} -> {len(summary)}ì")
            return summary
            
        except Exception as e:
            print(f"[âš ï¸ LLM ìš”ì•½ ì‹¤íŒ¨] {str(e)}")
            # ê°„ë‹¨í•œ ìš”ì•½ìœ¼ë¡œ fallback
            sentences = text.split('.')
            important_sentences = [s.strip() for s in sentences[:3] if len(s.strip()) > 10]
            return '. '.join(important_sentences) + '.' if important_sentences else text[:200] + "..."
            
    except Exception as e:
        print(f"[â—ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨] {str(e)}")
        return text[:200] + "..." if len(text) > 200 else text

# ===== 4. ê¸°ì¡´ extract_and_process_attachments í•¨ìˆ˜ í™•ì¥ =====
# ===== 4. ê¸°ì¡´ extract_and_process_attachments í•¨ìˆ˜ í™•ì¥ =====

def extract_and_process_attachments_enhanced(email_message, email_subject, email_id):
    """ì´ë©”ì¼ì—ì„œ ì²¨ë¶€íŒŒì¼ì„ ì¶”ì¶œí•˜ê³  YOLO + ë³´ê³ ì„œ ì²˜ë¦¬ (ìºì‹± ì¶”ê°€)"""
    global attachment_cache
    
    # âœ… ìºì‹œ í‚¤ ìƒì„± (ì´ë©”ì¼ ID + ì²¨ë¶€íŒŒì¼ í•´ì‹œ)
    cache_key = f"email_{email_id}"
    
    # âœ… ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    if cache_key in attachment_cache:
        print(f"[ğŸ“ ìºì‹œ ì‚¬ìš©] {email_subject[:30]}... - ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ìƒëµ")
        return attachment_cache[cache_key]
    
    attachments = []
    print(f"[ğŸ“ ìƒˆë¡œìš´ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬] {email_subject[:30]}...")
    
    for part in email_message.walk():
        if part.get_content_disposition() == 'attachment':
            filename = part.get_filename()
            
            if filename:
                # MIME ë””ì½”ë”©
                try:
                    decoded_parts = decode_header(filename)
                    if decoded_parts and decoded_parts[0]:
                        decoded_filename = decoded_parts[0]
                        if isinstance(decoded_filename[0], bytes):
                            filename = decoded_filename[0].decode(decoded_filename[1] or 'utf-8')
                        else:
                            filename = decoded_filename[0]
                except:
                    pass
                
                attachment_data = part.get_payload(decode=True)
                if not attachment_data:
                    continue
                
                # âœ… ê°œë³„ ì²¨ë¶€íŒŒì¼ë„ ìºì‹±
                file_hash = hashlib.md5(attachment_data).hexdigest()[:8]
                file_cache_key = f"file_{filename}_{file_hash}"
                
                if file_cache_key in attachment_cache:
                    print(f"[ğŸ“ íŒŒì¼ ìºì‹œ ì‚¬ìš©] {filename}")
                    attachments.append(attachment_cache[file_cache_key])
                    continue
                
                # íŒŒì¼ í™•ì¥ì ë° MIME íƒ€ì… í™•ì¸
                file_ext = Path(filename).suffix.lower()
                mime_type = part.get_content_type()
                
                print(f"[ğŸ“ ì²¨ë¶€íŒŒì¼ ë¶„ì„] {filename} ({file_ext}, {mime_type})")
                
                # íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬
                attachment_info = {
                    'filename': filename,
                    'size': len(attachment_data),
                    'mime_type': mime_type,
                    'extension': file_ext
                }
                
                try:
                    # 1. ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (ê¸°ì¡´ YOLO)
                    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
                    if file_ext in image_extensions:
                        # YOLO ì²˜ë¦¬
                        yolo_detections = process_image_with_yolo(attachment_data)
                        
                        # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë„ ì¶”ì¶œ (OCR) - í•œ ë²ˆë§Œ ì‹¤í–‰
                        ocr_result = extract_text_with_ocr(attachment_data, filename)
                        
                        attachment_info.update({
                            'type': 'image',
                            'yolo_detections': yolo_detections,
                            'detected_objects': [det['class'] for det in yolo_detections],
                            'object_count': len(yolo_detections),
                            'extracted_text': ocr_result.get('text', ''),
                            'ocr_success': ocr_result.get('success', False),
                            'processing_method': f"YOLO + {'OCR' if ocr_result.get('success') else 'No OCR'}"
                        })
                        
                        if ocr_result.get('success') and ocr_result.get('text'):
                            summary = summarize_document_with_llm(
                                ocr_result['text'], filename, 'image_with_text'
                            )
                            attachment_info['text_summary'] = summary
                    
                    # 2. PDF íŒŒì¼ ì²˜ë¦¬
                    elif file_ext == '.pdf' or 'pdf' in mime_type:
                        pdf_result = extract_text_from_pdf(attachment_data)
                        
                        attachment_info.update({
                            'type': 'document_pdf',
                            'extracted_text': pdf_result.get('text', ''),
                            'extraction_success': pdf_result.get('success', False),
                            'extraction_method': pdf_result.get('method', 'unknown'),
                            'pages': pdf_result.get('pages', 0)
                        })
                        
                        if pdf_result.get('success') and pdf_result.get('text'):
                            summary = summarize_document_with_llm(
                                pdf_result['text'], filename, 'PDF ë³´ê³ ì„œ'
                            )
                            attachment_info['document_summary'] = summary
                    
                    # 3. Word ë¬¸ì„œ ì²˜ë¦¬
                    elif file_ext == '.docx' or 'wordprocessingml' in mime_type:
                        docx_result = extract_text_from_docx(attachment_data)
                        
                        attachment_info.update({
                            'type': 'document_word',
                            'extracted_text': docx_result.get('text', ''),
                            'extraction_success': docx_result.get('success', False),
                            'paragraphs': docx_result.get('paragraphs', 0),
                            'tables': docx_result.get('tables', 0)
                        })
                        
                        if docx_result.get('success') and docx_result.get('text'):
                            summary = summarize_document_with_llm(
                                docx_result['text'], filename, 'Word ë¬¸ì„œ'
                            )
                            attachment_info['document_summary'] = summary
                    
                    # 4. PowerPoint ì²˜ë¦¬
                    elif file_ext == '.pptx' or 'presentationml' in mime_type:
                        pptx_result = extract_text_from_pptx(attachment_data)
                        
                        attachment_info.update({
                            'type': 'document_presentation',
                            'extracted_text': pptx_result.get('text', ''),
                            'extraction_success': pptx_result.get('success', False),
                            'slides': pptx_result.get('slides', 0)
                        })
                        
                        if pptx_result.get('success') and pptx_result.get('text'):
                            summary = summarize_document_with_llm(
                                pptx_result['text'], filename, 'PowerPoint í”„ë ˆì  í…Œì´ì…˜'
                            )
                            attachment_info['document_summary'] = summary
                    
                    # 5. Excel ì²˜ë¦¬
                    elif file_ext in ['.xlsx', '.xls'] or 'spreadsheetml' in mime_type:
                        xlsx_result = extract_text_from_xlsx(attachment_data)
                        
                        attachment_info.update({
                            'type': 'document_spreadsheet',
                            'extracted_text': xlsx_result.get('text', ''),
                            'extraction_success': xlsx_result.get('success', False),
                            'sheets': xlsx_result.get('sheets', 0),
                            'total_rows': xlsx_result.get('total_rows', 0)
                        })
                        
                        if xlsx_result.get('success') and xlsx_result.get('text'):
                            summary = summarize_document_with_llm(
                                xlsx_result['text'], filename, 'Excel ìŠ¤í”„ë ˆë“œì‹œíŠ¸'
                            )
                            attachment_info['document_summary'] = summary
                    
                    # 6. ê¸°íƒ€ íŒŒì¼
                    else:
                        attachment_info.update({
                            'type': 'other',
                            'processing_method': 'metadata_only'
                        })
                    
                    # âœ… ê°œë³„ íŒŒì¼ ìºì‹œì— ì €ì¥
                    attachment_cache[file_cache_key] = attachment_info
                    attachments.append(attachment_info)
                    
                    # ë¡œê·¸ ì¶œë ¥
                    if attachment_info.get('extraction_success'):
                        print(f"[âœ… ë¬¸ì„œ ì²˜ë¦¬ ì„±ê³µ] {filename}: {attachment_info.get('type')}")
                    elif attachment_info.get('object_count', 0) > 0:
                        print(f"[âœ… ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ê³µ] {filename}: {attachment_info['object_count']}ê°œ ê°ì²´")
                    else:
                        print(f"[ğŸ“ íŒŒì¼ ì •ë³´ë§Œ ìˆ˜ì§‘] {filename}")
                
                except Exception as e:
                    print(f"[â—ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜] {filename}: {str(e)}")
                    # ì²˜ë¦¬ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì €ì¥
                    attachment_info.update({
                        'type': 'error',
                        'error': str(e),
                        'processing_method': 'failed'
                    })
                    attachments.append(attachment_info)
    
    # âœ… ì „ì²´ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
    attachment_cache[cache_key] = attachments
    
    # âœ… ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    if len(attachment_cache) > 100:  # ìµœëŒ€ 100ê°œ í•­ëª©ë§Œ ìœ ì§€
        oldest_key = next(iter(attachment_cache))
        del attachment_cache[oldest_key]
        print(f"[ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬] ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ: {oldest_key}")
    
    print(f"[âœ… ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ] {len(attachments)}ê°œ ì²˜ë¦¬ë¨ (ìºì‹œ ì €ì¥)")
    return attachments
# app.pyì— ì¶”ê°€í•  í•¨ìˆ˜ (extract_and_process_attachments_enhanced í•¨ìˆ˜ ë‹¤ìŒì— ì¶”ê°€)

def generate_enhanced_attachment_summary(attachments):
    """í–¥ìƒëœ ì²¨ë¶€íŒŒì¼ ìš”ì•½ ìƒì„±"""
    if not attachments:
        return ""
    
    total_files = len(attachments)
    
    # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
    images = [att for att in attachments if att.get('type') == 'image']
    documents = [att for att in attachments if att.get('type', '').startswith('document_')]
    others = [att for att in attachments if att.get('type') not in ['image'] and not att.get('type', '').startswith('document_')]
    
    summary_parts = []
    
    if images:
        total_objects = sum(att.get('object_count', 0) for att in images)
        ocr_texts = [att for att in images if att.get('ocr_success')]
        
        if total_objects > 0:
            summary_parts.append(f"ì´ë¯¸ì§€ {len(images)}ê°œ({total_objects}ê°œ ê°ì²´)")
        else:
            summary_parts.append(f"ì´ë¯¸ì§€ {len(images)}ê°œ")
            
        if ocr_texts:
            summary_parts.append(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ {len(ocr_texts)}ê°œ")
    
    if documents:
        # ë¬¸ì„œ íƒ€ì…ë³„ ê°œìˆ˜ ê³„ì‚°
        doc_types = {}
        successful_extractions = 0
        
        for doc in documents:
            doc_type = doc.get('type', '').replace('document_', '')
            doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
            
            if doc.get('extraction_success'):
                successful_extractions += 1
        
        # ë¬¸ì„œ íƒ€ì…ë³„ í‘œì‹œ
        for doc_type, count in doc_types.items():
            type_names = {
                'pdf': 'PDF', 
                'word': 'Word', 
                'presentation': 'PPT', 
                'spreadsheet': 'Excel'
            }
            type_name = type_names.get(doc_type, doc_type.upper())
            summary_parts.append(f"{type_name} {count}ê°œ")
        
        # ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ë¬¸ì„œ ê°œìˆ˜ í‘œì‹œ
        if successful_extractions > 0:
            summary_parts.append(f"ìš”ì•½ ê°€ëŠ¥ {successful_extractions}ê°œ")
    
    if others:
        summary_parts.append(f"ê¸°íƒ€ {len(others)}ê°œ")
    
    if summary_parts:
        return f"ğŸ“ {total_files}ê°œ íŒŒì¼: " + ", ".join(summary_parts)
    else:
        return f"ğŸ“ {total_files}ê°œ íŒŒì¼"

@app.route('/api/document-summary', methods=['POST'])
def document_summary():
    """íŠ¹ì • ì²¨ë¶€íŒŒì¼ì˜ ìƒì„¸ ë¬¸ì„œ ìš”ì•½ ë°˜í™˜"""
    try:
        data = request.get_json()
        email_id = data.get("email_id")
        filename = data.get("filename", "")
        user_email = data.get("email", "")
        
        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        # ì„¸ì…˜ì—ì„œ í•´ë‹¹ ë©”ì¼ì˜ ì²¨ë¶€íŒŒì¼ ì°¾ê¸°
        last_emails = user_sessions[user_key].get('last_emails', [])
        target_attachment = None
        
        for email_data in last_emails:
            if email_data.get('id') == email_id:
                for attachment in email_data.get('attachments', []):
                    if attachment.get('filename') == filename:
                        target_attachment = attachment
                        break
                break
        
        if not target_attachment:
            return jsonify({"error": "í•´ë‹¹ ì²¨ë¶€íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ë¬¸ì„œ ìš”ì•½ ì •ë³´ ë°˜í™˜
        response_data = {
            "success": True,
            "filename": filename,
            "file_type": target_attachment.get('type', 'unknown'),
            "size": target_attachment.get('size', 0),
            "extraction_success": target_attachment.get('extraction_success', False)
        }
        
        # íƒ€ì…ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
        if target_attachment.get('type') == 'image':
            response_data.update({
                "yolo_detections": target_attachment.get('detected_objects', []),
                "object_count": target_attachment.get('object_count', 0),
                "ocr_text": target_attachment.get('extracted_text', ''),
                "text_summary": target_attachment.get('text_summary', '')
            })
        
        elif target_attachment.get('type', '').startswith('document_'):
            response_data.update({
                "extracted_text": target_attachment.get('extracted_text', '')[:1000],  # ì²˜ìŒ 1000ìë§Œ
                "document_summary": target_attachment.get('document_summary', ''),
                "extraction_method": target_attachment.get('extraction_method', ''),
                "full_text_available": len(target_attachment.get('extracted_text', '')) > 1000
            })
            
            # íŒŒì¼ íƒ€ì…ë³„ ì¶”ê°€ ì •ë³´
            if target_attachment.get('pages'):
                response_data['pages'] = target_attachment['pages']
            if target_attachment.get('slides'):
                response_data['slides'] = target_attachment['slides']
            if target_attachment.get('sheets'):
                response_data['sheets'] = target_attachment['sheets']
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"[â—ë¬¸ì„œ ìš”ì•½ API ì˜¤ë¥˜] {str(e)}")
        return jsonify({"error": str(e)}), 500
    
# ===== ê¸°ì¡´ Qwen ê´€ë ¨ í•¨ìˆ˜ë“¤ =====
def load_qwen_model():
    """Qwen ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    global qwen_model, qwen_tokenizer
    
    if qwen_model is None:
        print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
        try:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model_id = "Qwen/Qwen1.5-1.8B-Chat"
            
            qwen_tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
            qwen_model = AutoModelForCausalLM.from_pretrained(
                model_id,
                device_map="auto",
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                trust_remote_code=True
            )
            qwen_model.eval()
            print("[âœ… Qwen ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
        except Exception as e:
            print(f"[â—Qwen ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
            # Qwen ë¡œë”© ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ê¸°ëŠ¥ì€ ì •ìƒ ì‘ë™í•˜ë„ë¡

def extract_search_target_with_qwen(text):
    """Qwenì„ ì´ìš©í•˜ì—¬ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ"""
    global qwen_model, qwen_tokenizer
    
    # ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë”© ì‹œë„
    if qwen_model is None:
        load_qwen_model()
    
    # ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í•œ ê²½ìš° ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ fallback
    if qwen_model is None:
        print("[âš ï¸ Qwen ëª¨ë¸ ì—†ìŒ - ê°„ë‹¨ ì¶”ì¶œ ì‚¬ìš©]")
        words = text.split()
        return " ".join(words[-2:]) if len(words) >= 2 else text
    
    try:
        prompt = (
            "<|im_start|>system\nYou are an email assistant. "
            "Your job is to extract the email address or name the user is referring to. "
            "You must always respond in the format: The user is referring to ... \n"
            "<|im_end|>\n"
            f"<|im_start|>user\n{text}<|im_end|>\n"
            "<|im_start|>assistant\n"
        )
        
        inputs = qwen_tokenizer(prompt, return_tensors="pt").to(qwen_model.device)
        
        with torch.no_grad():
            outputs = qwen_model.generate(
                **inputs,
                max_new_tokens=50,
                do_sample=False,
                eos_token_id=qwen_tokenizer.eos_token_id
            )
        
        decoded_output = qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)
        print("\n Qwen ì‘ë‹µ ì „ì²´:\n", decoded_output)
        # "assistant" ì´í›„ í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜´
        if "assistant" in decoded_output:
            after_assistant = decoded_output.split("assistant")[-1].strip()
            prefix = "The user is referring to "
            if prefix in after_assistant:
                result = after_assistant.split(prefix)[-1].strip().rstrip(".").strip('"')
                return result
        

    except Exception as e:
        print(f"[âš ï¸ Qwen ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ fallback
        words = text.split()
        return " ".join(words[-2:]) if len(words) >= 2 else text

def search_emails_by_target(emails, search_target):
    """ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰ ëŒ€ìƒìœ¼ë¡œ í•„í„°ë§"""
    results = []
    search_lower = search_target.lower()
    
    for mail in emails:
        # from í•„ë“œì—ì„œ ê²€ìƒ‰
        if search_lower in mail["from"].lower():
            results.append(mail)
        # ì œëª©ì—ì„œë„ ê²€ìƒ‰
        elif search_lower in mail["subject"].lower():
            results.append(mail)
        # ì´ë©”ì¼ ì£¼ì†Œë§Œ ì¶”ì¶œí•´ì„œ ê²€ìƒ‰
        elif "@" in search_target:
            # ì´ë©”ì¼ ì£¼ì†Œ íŒ¨í„´ ë§¤ì¹­
            email_pattern = r'<([^>]+)>'
            email_match = re.search(email_pattern, mail["from"])
            if email_match and search_lower in email_match.group(1).lower():
                results.append(mail)
    
    return results

def get_session_id():
    """ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
    if 'session_id' not in session:
        session['session_id'] = str(uuid.uuid4())
    return session['session_id']

def get_user_key(email):
    """ì´ë©”ì¼ ê¸°ë°˜ ì‚¬ìš©ì í‚¤ ìƒì„±"""
    return hashlib.md5(email.encode()).hexdigest()

# ìš”ì•½ ëª¨ë¸ ë¡œë”©
summarizer = pipeline("summarization", model="facebook/bart-large-cnn", tokenizer="facebook/bart-large-cnn")

def build_ai_reply_prompt(sender, subject, body):
    """AI ë‹µì¥ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""
You are a helpful email assistant that writes professional email replies.

Please read the following email and write a polite, professional reply in English:

---
From: {sender}
Subject: {subject}
Body: {body}
---

Instructions:
1. Identify the purpose of the email (invitation, question, information request, scheduling, etc.)
2. Write a concise (3-4 sentences), polite reply that directly addresses the purpose
3. Use a friendly yet professional tone
4. Only output the reply text (no analysis, no quotes, no original email content)

Reply:
""".strip()

# ===== API ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

@app.route('/api/email-search', methods=['POST'])
def email_search():
    """ì´ë©”ì¼ ê²€ìƒ‰ API - ë³€ìˆ˜ëª… ì¶©ëŒ í•´ê²°"""
    try:
        data = request.get_json()
        user_input = data.get("user_input", "").strip()
        user_email = data.get("email", "")  # âœ… ë³€ìˆ˜ëª… ë³€ê²½
        app_password = data.get("app_password", "")
        
        print(f"[ğŸ” ì´ë©”ì¼ ê²€ìƒ‰ ìš”ì²­] ì‚¬ìš©ì: {user_email}, ì…ë ¥: {user_input}")
        
        if not all([user_input, user_email, app_password]):
            return jsonify({"error": "ì‚¬ìš©ì ì…ë ¥, ì´ë©”ì¼, ì•± ë¹„ë°€ë²ˆí˜¸ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        print("[ğŸ¯ ì‹¤ì œ ë©”ì¼ ê²€ìƒ‰ ì‹œì‘]")
        
        # Qwenì„ ì´ìš©í•´ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ
        try:
            search_target = extract_search_target_with_qwen(user_input)
            print(f"[ğŸ¯ ê²€ìƒ‰ ëŒ€ìƒ ì¶”ì¶œ] '{search_target}'")
        except Exception as e:
            print(f"[âš ï¸ Qwen ì¶”ì¶œ ì‹¤íŒ¨] {str(e)}")
            # ê°„ë‹¨í•œ ì´ë©”ì¼ ì¶”ì¶œ fallback
            import re
            email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
            emails_found = re.findall(email_pattern, user_input)
            if emails_found:
                search_target = emails_found[0]
            else:
                words = user_input.split()
                search_target = " ".join(words[-2:]) if len(words) >= 2 else user_input
        
        print(f"[ğŸ” ìµœì¢… ê²€ìƒ‰ ëŒ€ìƒ] '{search_target}'")
        
        # ë©”ì¼ ì„œë²„ ì—°ê²° ë° ê²€ìƒ‰
        try:
            mail = imaplib.IMAP4_SSL("imap.gmail.com")
            mail.login(user_email, app_password)  # âœ… ë³€ìˆ˜ëª… ìˆ˜ì •
            mail.select("inbox")
            print("[âœ… ë©”ì¼ ì„œë²„ ì—°ê²° ì„±ê³µ]")
            
            # ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •
            N = 100
            status, data_result = mail.search(None, "ALL")
            all_mail_ids = data_result[0].split()
            mail_ids = all_mail_ids[-N:]  # ìµœê·¼ Nê°œ
            
            print(f"[ğŸ“Š ê²€ìƒ‰ ë²”ìœ„] ì´ {len(all_mail_ids)}ê°œ ì¤‘ ìµœê·¼ {len(mail_ids)}ê°œ ê²€ìƒ‰")
            
            emails_found = []
            processed_count = 0
            
            for msg_id in mail_ids:
                try:
                    _, msg_data = mail.fetch(msg_id, "(RFC822)")
                    if not msg_data or not msg_data[0]:
                        continue
                        
                    # âœ… ì˜¬ë°”ë¥¸ ëª¨ë“ˆ ì‚¬ìš©
                    msg = email_module.message_from_bytes(msg_data[0][1])
                    processed_count += 1
                    
                    # ì œëª© ë””ì½”ë”©
                    raw_subject = msg.get("Subject", "")
                    try:
                        decoded_parts = decode_header(raw_subject)
                        if decoded_parts and decoded_parts[0]:
                            decoded_subject = decoded_parts[0]
                            subject_bytes = decoded_subject[0]
                            subject_encoding = decoded_subject[1]
                            
                            if isinstance(subject_bytes, bytes):
                                if subject_encoding is None:
                                    subject_encoding = 'utf-8'
                                try:
                                    subject = subject_bytes.decode(subject_encoding)
                                except (UnicodeDecodeError, LookupError):
                                    for fallback_encoding in ['utf-8', 'latin-1', 'cp949', 'euc-kr']:
                                        try:
                                            subject = subject_bytes.decode(fallback_encoding)
                                            break
                                        except (UnicodeDecodeError, LookupError):
                                            continue
                                    else:
                                        subject = subject_bytes.decode('utf-8', errors='ignore')
                            else:
                                subject = str(subject_bytes)
                        else:
                            subject = "(ì œëª© ì—†ìŒ)"
                    except Exception as e:
                        subject = raw_subject if raw_subject else "(ì œëª© ì—†ìŒ)"
                    
                    # ë°œì‹ ì ì •ë³´
                    name, addr = parseaddr(msg.get("From"))
                    from_field = f"{name} <{addr}>" if name else addr
                    
                    # ë‚ ì§œ ì²˜ë¦¬
                    raw_date = msg.get("Date", "")
                    try:
                        date_obj = parsedate_to_datetime(raw_date)
                        date_str = date_obj.strftime("%Y-%m-%d %H:%M:%S")
                    except:
                        date_str = raw_date[:19] if len(raw_date) >= 19 else raw_date
                    
                    # ë³¸ë¬¸ ì¶”ì¶œ
                    body = ""
                    try:
                        if msg.is_multipart():
                            for part in msg.walk():
                                if part.get_content_type() == "text/plain" and not part.get("Content-Disposition"):
                                    charset = part.get_content_charset() or "utf-8"
                                    body += part.get_payload(decode=True).decode(charset, errors="ignore")
                        else:
                            charset = msg.get_content_charset() or "utf-8"
                            body = msg.get_payload(decode=True).decode(charset, errors="ignore")
                        
                        body = body.strip()
                    except Exception as e:
                        body = ""
                    
                    # ê²€ìƒ‰ ëŒ€ìƒê³¼ ë§¤ì¹­ í™•ì¸
                    search_in = f"{subject} {from_field} {body}".lower()
                    search_lower = search_target.lower()
                    
                    # ì´ë©”ì¼ ì£¼ì†Œë‚˜ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
                    if (search_lower in search_in or 
                        any(part.strip() in search_in for part in search_lower.split() if part.strip())):
                        
                        emails_found.append({
                            "id": int(msg_id.decode()) if isinstance(msg_id, bytes) else int(msg_id),
                            "subject": subject,
                            "from": from_field,
                            "date": date_str,
                            "body": body[:500]  # ì²˜ìŒ 500ìë§Œ
                        })
                        
                        print(f"[âœ… ë§¤ì¹­ ë°œê²¬] {from_field} -> {subject[:30]}...")
                        
                        if len(emails_found) >= 10:  # ìµœëŒ€ 10ê°œ
                            break
                            
                except Exception as e:
                    print(f"[âš ï¸ ë©”ì¼ ì²˜ë¦¬ ì˜¤ë¥˜] {str(e)}")
                    continue
            
            mail.close()
            mail.logout()
            
            print(f"[ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ] {processed_count}ê°œ ì²˜ë¦¬, {len(emails_found)}ê°œ ë°œê²¬")
            
            return jsonify({
                "success": True,
                "search_target": search_target,
                "results": emails_found,
                "total_searched": processed_count,
                "found_count": len(emails_found),
                "confidence": 1.0,
                "detected_intent": "email_search_completed"
            })
            
        except Exception as e:
            print(f"[â—ë©”ì¼ ì„œë²„ ì˜¤ë¥˜] {str(e)}")
            return jsonify({
                "success": False,
                "error": f"ë©”ì¼ ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}",
                "search_target": search_target if 'search_target' in locals() else user_input
            }), 500
            
    except Exception as e:
        print(f"[â—ì´ë©”ì¼ ê²€ìƒ‰ ì˜¤ë¥˜] {str(e)}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/logout', methods=['POST'])
def logout_user():
    """ì‚¬ìš©ì ë¡œê·¸ì•„ì›ƒ - ì„¸ì…˜ ë°ì´í„° ì‚­ì œ"""
    try:
        data = request.get_json()
        email = data.get('email', '')
        
        if email:
            clear_user_session(email)
            session.clear()  # Flask ì„¸ì…˜ë„ ì‚­ì œ
            
            return jsonify({
                'success': True,
                'message': 'ë¡œê·¸ì•„ì›ƒ ì„±ê³µ'
            })
        else:
            return jsonify({'error': 'ì´ë©”ì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
            
    except Exception as e:
        print(f"[â—ë¡œê·¸ì•„ì›ƒ ì‹¤íŒ¨] {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/generate-ai-reply', methods=['POST'])
def generate_ai_reply():
    """AI ë‹µì¥ ìƒì„± API"""
    try:
        data = request.get_json()
        sender = data.get('sender', '')
        subject = data.get('subject', '')
        body = data.get('body', '')
        current_user_email = data.get('email', '')  # í˜„ì¬ ì‚¬ìš©ì ì´ë©”ì¼ ì¶”ê°€
        
        print(f"[ğŸ¤– AI ë‹µì¥ ìš”ì²­] User: {current_user_email}, From: {sender}, Subject: {subject[:50]}...")
        
        if not all([sender, subject, body, current_user_email]):
            return jsonify({'error': 'ë°œì‹ ì, ì œëª©, ë³¸ë¬¸, ì‚¬ìš©ì ì´ë©”ì¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(current_user_email)
        if user_key not in user_sessions:
            return jsonify({'error': 'ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 401
        
        # Hugging Face í† í° í™•ì¸
        hf_token = os.getenv("HF_TOKEN")
        if not hf_token:
            return jsonify({'error': 'HF_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.'}), 500
        
        # InferenceClient ìƒì„±
        client = InferenceClient(
            model="Qwen/Qwen2.5-7B-Instruct",
            token=hf_token
        )
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_prompt = build_ai_reply_prompt(sender, subject, body)
        
        # AI ë‹µì¥ ìƒì„±
        messages = [
            {"role": "system", "content": "You are a helpful email assistant that writes professional email replies."},
            {"role": "user", "content": user_prompt}
        ]
        
        response = client.chat_completion(
            messages=messages,
            max_tokens=256,
            temperature=0.7
        )
        
        # ë‹µì¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ai_reply = response.choices[0].message.content.strip()
        
        print(f"[âœ… AI ë‹µì¥ ìƒì„± ì™„ë£Œ] User: {current_user_email}, ê¸¸ì´: {len(ai_reply)}ì")
        
        return jsonify({
            'success': True,
            'ai_reply': ai_reply
        })
        
    except Exception as e:
        print(f"[â—AI ë‹µì¥ ìƒì„± ì‹¤íŒ¨] {str(e)}")
        traceback.print_exc()
        return jsonify({'error': f'AI ë‹µì¥ ìƒì„± ì‹¤íŒ¨: {str(e)}'}), 500

# âœ… ìˆ˜ì •ëœ summary í•¨ìˆ˜ - ì²¨ë¶€íŒŒì¼ YOLO ì²˜ë¦¬ ì¶”ê°€
@app.route('/api/summary', methods=['POST'])
def summary():
    try:
        data = request.get_json()
        username = data.get("email")
        app_password = data.get("app_password")

        # ì‚¬ìš©ì í‚¤ ìƒì„± ë° ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(username)
        
        print(f"[ğŸ“§ ë©”ì¼ ìš”ì²­] ì‚¬ìš©ì: {username}")
        
        # ë¬¸ìì—´ ë‚ ì§œë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
        after_date = data.get("after")
        after_dt = None
        if after_date:
            try:
                after_date_clean = after_date.replace("Z", "+00:00")
                after_dt = datetime.fromisoformat(after_date_clean)
                after_dt = after_dt.replace(tzinfo=None)
                print(f"[ğŸ“… í•„í„°ë§ ê¸°ì¤€] {after_dt} ì´í›„ ë©”ì¼ë§Œ ê°€ì ¸ì˜´")
            except Exception as e:
                print("[âš ï¸ after_date íŒŒì‹± ì‹¤íŒ¨]", e)

        # ë©”ì¼ ì„œë²„ ì—°ê²°
        mail = imaplib.IMAP4_SSL("imap.gmail.com")
        mail.login(username, app_password)
        mail.select("inbox")

        # ë©”ì¼ ìˆ˜ ë™ì  ê²°ì •
        if after_dt:
            N = 10
            print(f"[ğŸ”„ ìƒˆë¡œê³ ì¹¨] ìµœê·¼ {N}ê°œ ë©”ì¼ì—ì„œ {after_dt} ì´í›„ ë©”ì¼ ê²€ìƒ‰")
        else:
            N = 5
            print(f"[ğŸ†• ì²« ë¡œë”©] ìµœê·¼ {N}ê°œ ë©”ì¼ ê°€ì ¸ì˜´")

        status, data = mail.search(None, "ALL")
        all_mail_ids = data[0].split()
        
        # ìµœì‹  ë©”ì¼ë¶€í„° ì²˜ë¦¬í•˜ë„ë¡ ìˆœì„œ ìˆ˜ì •
        mail_ids = all_mail_ids[-N:]
        mail_ids.reverse()

        emails = []
        processed_count = 0

        for msg_id in mail_ids:
            status, msg_data = mail.fetch(msg_id, "(RFC822)")
            if not msg_data or not msg_data[0]:
                continue

            raw_msg = msg_data[0][1]
            msg = email.message_from_bytes(raw_msg)

            # ì œëª© ë””ì½”ë”©
            raw_subject = msg.get("Subject", "")
            decoded_parts = decode_header(raw_subject)
            if decoded_parts:
                decoded_subject = decoded_parts[0]
                subject = decoded_subject[0].decode(decoded_subject[1]) if isinstance(decoded_subject[0], bytes) else decoded_subject[0]
            else:
                subject = "(ì œëª© ì—†ìŒ)"

            # ë³´ë‚´ëŠ” ì‚¬ëŒ
            name, addr = parseaddr(msg.get("From"))
            from_field = f"{name} <{addr}>" if name else addr

            # ë‚ ì§œ ì²˜ë¦¬
            raw_date = msg.get("Date", "")
            try:
                date_obj = parsedate_to_datetime(raw_date)
                date_obj = date_obj.replace(tzinfo=None)
                date_str = date_obj.strftime("%Y-%m-%d %H:%M:%S")
            except:
                date_obj = None
                date_str = raw_date[:19] if len(raw_date) >= 19 else raw_date

            # after_date í•„í„°ë§
            if after_dt and date_obj:
                if date_obj <= after_dt:
                    print(f"[â­ï¸ ê±´ë„ˆë›°ê¸°] {date_str} (ê¸°ì¤€: {after_dt})")
                    continue
                else:
                    print(f"[âœ… í¬í•¨] {date_str} - {subject[:30]}...")

            # ë³¸ë¬¸ ì¶”ì¶œ
            body = ""
            if msg.is_multipart():
                for part in msg.walk():
                    if part.get_content_type() == "text/plain" and not part.get("Content-Disposition"):
                        charset = part.get_content_charset() or "utf-8"
                        body += part.get_payload(decode=True).decode(charset, errors="ignore")
            else:
                charset = msg.get_content_charset() or "utf-8"
                body = msg.get_payload(decode=True).decode(charset, errors="ignore")

            body = body.strip()
            if not body:
                body = ""

            # âœ… ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ ë° YOLO ì²˜ë¦¬ ì¶”ê°€
            email_id_str = msg_id.decode() if isinstance(msg_id, bytes) else str(msg_id)
            print(f"[ğŸ“ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘] ë©”ì¼: {subject[:30]}... (ID: {email_id_str})")
            
            # ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
            attachments = []
            try:
                print(f"[ğŸ” ë©€í‹°íŒŒíŠ¸ í™•ì¸] {msg.is_multipart()}")
                
                if msg.is_multipart():
                    attachment_count = 0
                    for part in msg.walk():
                        content_disp = part.get_content_disposition()
                        if content_disp == 'attachment':
                            attachment_count += 1
                            filename = part.get_filename()
                            print(f"    âœ… ì²¨ë¶€íŒŒì¼ {attachment_count}: {filename}")
                    
                    print(f"[ğŸ“Š ì²¨ë¶€íŒŒì¼ ê°œìˆ˜] {attachment_count}ê°œ")
                    
                    if attachment_count > 0:
                        print(f"[ğŸ“ ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì‹œì‘] {attachment_count}ê°œ ë°œê²¬")
                        attachments = extract_and_process_attachments_enhanced(msg, subject, email_id_str)
                        print(f"[âœ… ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ] {len(attachments)}ê°œ ì²˜ë¦¬ë¨")
                        
                        # ì²˜ë¦¬ ê²°ê³¼ ìƒì„¸ ë¡œê·¸
                        for i, att in enumerate(attachments):
                            print(f"  ğŸ“ {i+1}. {att.get('filename', 'Unknown')} ({att.get('type', 'unknown')})")
                            if att.get('document_summary'):
                                print(f"       ğŸ“„ ìš”ì•½: {att['document_summary'][:50]}...")
                            if att.get('yolo_detections'):
                                print(f"       ğŸ¤– YOLO: {len(att['yolo_detections'])}ê°œ ê°ì²´")
                    else:
                        print(f"[â„¹ï¸ ì²¨ë¶€íŒŒì¼ ì—†ìŒ]")
                else:
                    print(f"[â„¹ï¸ ë‹¨ì¼ íŒŒíŠ¸ ë©”ì‹œì§€ - ì²¨ë¶€íŒŒì¼ ì—†ìŒ]")
                    
            except Exception as e:
                print(f"[â—ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜] {str(e)}")
                import traceback
                traceback.print_exc()
                attachments = []
            # ===== ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ ì¶”ê°€ ë =====

            # ë¶„ë¥˜ ì‹¤í–‰
            try:
                text_inputs = [body] + candidate_labels
                result = embed.text(text_inputs, model='nomic-embed-text-v1', task_type='classification')
                embedding_list = result['embeddings']
                email_embedding = [embedding_list[0]]
                label_embeddings = embedding_list[1:]
                scores = cosine_similarity(email_embedding, label_embeddings)[0]
                best_index = scores.argmax()
                classification_tag = candidate_labels[best_index]
                confidence = scores[best_index]
                print(f"[ğŸ·ï¸ ë¶„ë¥˜] {classification_tag} (ì‹ ë¢°ë„: {confidence:.3f})")
            except Exception as e:
                print("[âš ï¸ ë¶„ë¥˜ ì‹¤íŒ¨]", str(e))
                classification_tag = "unknown"

            # ìš”ì•½ ì‹¤í–‰
            try:
                if not body:
                    summary_text = "(ë³¸ë¬¸ ì—†ìŒ)"
                else:
                    safe_text = body[:1000]
                    if len(safe_text) < 50:
                        summary_text = safe_text
                    else:
                        summary_text = summarizer(
                            safe_text,
                            max_length=80,
                            min_length=30,
                            do_sample=False
                        )[0]["summary_text"]
            except Exception as e:
                print("[âš ï¸ ìš”ì•½ ì‹¤íŒ¨]", str(e))
                summary_text = body[:150] + "..." if body else "(ìš”ì•½ ì‹¤íŒ¨)"

            # íƒœê·¸ ì¶”ì •
            typ, flag_data = mail.fetch(msg_id, "(FLAGS)")
            if flag_data and flag_data[0]:
                flags_bytes = flag_data[0]
                flags_str = flags_bytes.decode() if isinstance(flags_bytes, bytes) else str(flags_bytes)
            else:
                flags_str = ""

            tag = "ë°›ì€"
            if "\\Important" in flags_str:
                tag = "ì¤‘ìš”"
            elif "\\Junk" in flags_str or "\\Spam" in flags_str:
                tag = "ìŠ¤íŒ¸"

            # âœ… ë©”ì¼ ê°ì²´ì— ì²¨ë¶€íŒŒì¼ ì •ë³´ ì¶”ê°€
            emails.append({
                "id": int(msg_id.decode()) if isinstance(msg_id, bytes) else int(msg_id),
                "subject": subject,
                "from": from_field,
                "date": date_str,
                "body": body[:1000],
                "tag": tag,
                "summary": summary_text,
                "classification": classification_tag,
                "attachments": attachments,  # âœ… ì²¨ë¶€íŒŒì¼ ë°°ì—´
                "has_attachments": len(attachments) > 0,  # âœ… ì²¨ë¶€íŒŒì¼ ìœ ë¬´
                "attachment_summary": generate_enhanced_attachment_summary(attachments) if attachments else ""  # âœ… ì²¨ë¶€íŒŒì¼ ìš”ì•½
            })
            
            # ì²˜ë¦¬ ì™„ë£Œ ë¡œê·¸
            print(f"[âœ… ë©”ì¼ ì™„ë£Œ] {subject[:30]}... (ì²¨ë¶€íŒŒì¼: {len(attachments)}ê°œ)")
            processed_count += 1

        # ë°±ì—”ë“œì—ì„œë„ ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
        emails.sort(key=lambda x: x['date'], reverse=True)
        
        # ì‚¬ìš©ìë³„ ì„¸ì…˜ì— ë©”ì¼ ë°ì´í„° ì €ì¥
        if user_key not in user_sessions:
            user_sessions[user_key] = {}
        
        user_sessions[user_key]['last_emails'] = emails
        user_sessions[user_key]['last_update'] = datetime.now().isoformat()
        
        print(f"[ğŸ“Š ê²°ê³¼] ì‚¬ìš©ì: {username}, ì´ {processed_count}ê°œ ë©”ì¼ ì²˜ë¦¬ ì™„ë£Œ")
        if emails:
            print(f"[ğŸ“… ë²”ìœ„] {emails[-1]['date']} ~ {emails[0]['date']}")

        return jsonify({
            "emails": emails,
            "user_session": user_key[:8] + "...",  # ë””ë²„ê·¸ìš©
            "cache_info": f"ì„¸ì…˜ì— {len(emails)}ê°œ ë©”ì¼ ì €ì¥ë¨"
        })

    except Exception as e:
        print("[â—ì—ëŸ¬ ë°œìƒ]", str(e))
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route('/api/chatbot', methods=['POST'])
def chatbot():
    try:
        data = request.get_json()
        user_input = data.get("user_input", "").strip()
        user_email = data.get("email", "")
        app_password = data.get("app_password", "")
        
        print(f"[ğŸ¤– ì±—ë´‡ ìš”ì²­] ì‚¬ìš©ì: {user_email}, ì…ë ¥: {user_input}")
        
        if not user_input:
            return jsonify({"error": "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400
        
        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            print(f"[âš ï¸ ì„¸ì…˜ ì—†ìŒ] {user_email} ì‚¬ìš©ìì˜ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        # âœ… 1. ì˜ì–´ Embedding ê¸°ë°˜ ë¶„ë¥˜ (ê¸°ì¡´ ë°©ì‹)
        candidate_labels = [
            "correct the vocabulary, spelling",
            "image generation using text", 
            "find something",
            "email search for a person"
        ]
        
        text_inputs = [user_input] + candidate_labels
        result = embed.text(text_inputs, model='nomic-embed-text-v1', task_type='classification')
        
        embedding_list = result['embeddings']
        email_embedding = [embedding_list[0]]
        label_embeddings = embedding_list[1:]
        
        scores = cosine_similarity(email_embedding, label_embeddings)[0]
        best_index = scores.argmax()
        embedding_score = scores[best_index]
        embedding_label = candidate_labels[best_index]
        
        # âœ… 2. í•œêµ­ì–´ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        user_input_lower = user_input.lower()
        
        korean_patterns = {
            "grammar": {
                "keywords": ["êµì •", "ë§ì¶¤ë²•", "ë¬¸ë²•", "í‹€ë ¸", "ê³ ì³", "ìˆ˜ì •"],
                "action": "grammar_correction"
            },
            "image": {
                "keywords": ["ì´ë¯¸ì§€", "ê·¸ë¦¼", "ì‚¬ì§„", "ê·¸ë ¤", "ë§Œë“¤ì–´", "ìƒì„±"],
                "action": "image_generation"
            },
            "person_search": {
                "keywords": ["ë‹˜", "ì”¨"],
                "required": ["ë©”ì¼", "ì´ë©”ì¼"],  # ë‘˜ ë‹¤ ìˆì–´ì•¼ í•¨
                "action": "person_search"
            },
            "general_search": {
                "keywords": ["ì°¾ì•„", "ê²€ìƒ‰", "ì°¾ê¸°"],
                "action": "email_search"
            }
        }
        
        korean_result = {"action": None, "confidence": 0.0, "matched_keywords": []}
        
        for pattern_name, pattern_info in korean_patterns.items():
            matched_keywords = []
            
            # ì¼ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in pattern_info["keywords"]:
                if keyword in user_input_lower:
                    matched_keywords.append(keyword)
            
            # í•„ìˆ˜ í‚¤ì›Œë“œ í™•ì¸ (person_searchìš©)
            if "required" in pattern_info:
                required_found = any(req in user_input_lower for req in pattern_info["required"])
                if not required_found:
                    continue
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ë§¤ì¹­ëœ í‚¤ì›Œë“œ ë¹„ìœ¨)
            if matched_keywords:
                confidence = len(matched_keywords) / len(pattern_info["keywords"])
                
                # person_searchëŠ” íŠ¹ë³„ ì²˜ë¦¬ (í•„ìˆ˜ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤)
                if pattern_name == "person_search" and "required" in pattern_info:
                    confidence += 0.3  # ë³´ë„ˆìŠ¤
                
                if confidence > korean_result["confidence"]:
                    korean_result = {
                        "action": pattern_info["action"],
                        "confidence": confidence,
                        "matched_keywords": matched_keywords
                    }
        
        print(f"[ğŸ”¤ í•œêµ­ì–´ ë¶„ì„] {korean_result['action']} (ì‹ ë¢°ë„: {korean_result['confidence']:.3f})")
        print(f"[ğŸŒ ì˜ì–´ ë¶„ì„] {embedding_label} (ì‹ ë¢°ë„: {embedding_score:.3f})")
        
        # âœ… 3. ìµœì¢… ì˜ë„ ê²°ì • (ë” ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ)
        
        # ì˜ì–´ embedding ê²°ê³¼ë¥¼ actionìœ¼ë¡œ ë³€í™˜
        embedding_action_map = {
            "correct the vocabulary, spelling": "grammar_correction",
            "image generation using text": "image_generation", 
            "find something": "email_search",
            "email search for a person": "person_search"
        }
        
        embedding_action = embedding_action_map.get(embedding_label, "unknown")
        embedding_threshold = 0.25  # ì„ê³„ê°’ ë‚®ì¶¤
        
        # ìµœì¢… ê²°ì •
        if korean_result["confidence"] >= 0.3 and korean_result["confidence"] > embedding_score:
            # í•œêµ­ì–´ í‚¤ì›Œë“œ ìš°ì„ 
            final_action = korean_result["action"]
            final_confidence = korean_result["confidence"]
            detection_method = "korean_keywords"
            
        elif embedding_score >= embedding_threshold:
            # ì˜ì–´ embedding ì‚¬ìš©
            final_action = embedding_action
            final_confidence = embedding_score
            detection_method = "english_embedding"
            
        else:
            # ë‘˜ ë‹¤ ë‚®ìœ¼ë©´ unknown
            final_action = "unknown"
            final_confidence = max(korean_result["confidence"], embedding_score)
            detection_method = "low_confidence"
        
        print(f"[ğŸ¯ ìµœì¢… ê²°ì •] {final_action} (ë°©ë²•: {detection_method}, ì‹ ë¢°ë„: {final_confidence:.3f})")
        
        # âœ… 4. ê° ê¸°ëŠ¥ë³„ ì‹¤í–‰
        if final_action == "grammar_correction":
            response = handle_grammar_correction(user_input)
            
        elif final_action == "image_generation":
            response = handle_image_generation(user_input)
            
        elif final_action == "email_search":
            response = handle_general_search(user_input, user_email, app_password)
            
        elif final_action == "person_search":
            response = handle_person_search(user_input, user_email, app_password)
            
        else:
            response = """â“ ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ì„ ì‹œë„í•´ì£¼ì„¸ìš”.

ğŸ”§ **ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤:**
â€¢ **ë¬¸ë²•/ë§ì¶¤ë²• êµì •**: "ì´ ë¬¸ì¥ êµì •í•´ì£¼ì„¸ìš”" / "correct this sentence"
â€¢ **ì´ë¯¸ì§€ ìƒì„±**: "ê³ ì–‘ì´ ê·¸ë¦¼ ê·¸ë ¤ì¤˜" / "generate cat image"  
â€¢ **ë©”ì¼ ê²€ìƒ‰**: "íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜" / "find meeting emails"
â€¢ **ì‚¬ëŒë³„ ë©”ì¼**: "ê¹€ì² ìˆ˜ë‹˜ ë©”ì¼ ê²€ìƒ‰" / "search john@company.com emails"

ğŸ’¡ **Example / ì˜ˆì‹œ:**
- í•œêµ­ì–´: "ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤ êµì •í•´ì£¼ì„¸ìš”"
- English: "correct the grammar: I can't attend meeting today"
- í˜¼í•©: "find í”„ë¡œì íŠ¸ ê´€ë ¨ emails" """
        
        return jsonify({
            "response": response,
            "action": final_action,
            "confidence": float(final_confidence),
            "detected_intent": final_action,
            "detection_method": detection_method,
            "debug_info": {
                "korean": f"{korean_result['action']} ({korean_result['confidence']:.3f})",
                "english": f"{embedding_action} ({embedding_score:.3f})",
                "final": f"{final_action} via {detection_method}"
            }
        }), 200
        
    except Exception as e:
        print("[â—ì±—ë´‡ ì˜¤ë¥˜]", str(e))
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500
        
# âœ… 4. ê° ê¸°ëŠ¥ë³„ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤
# handle_grammar_correction í•¨ìˆ˜ë¥¼ ì´ê²ƒìœ¼ë¡œ êµì²´í•˜ì„¸ìš”

def handle_grammar_correction(user_input):
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” ë¬¸ë²• ë° ë§ì¶¤ë²• êµì • ê¸°ëŠ¥"""
    try:
        # êµì •í•  í…ìŠ¤íŠ¸ ì¶”ì¶œ
        correction_text = user_input
        
        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ì œê±°
        remove_words = ["êµì •í•´ì£¼ì„¸ìš”", "êµì •í•´ì¤˜", "ë§ì¶¤ë²•", "ë¬¸ë²•", "correct", "spelling", "check", "fix"]
        for word in remove_words:
            correction_text = correction_text.replace(word, "").strip()
        
        if not correction_text:
            return "ğŸ“ **ë¬¸ë²• ë° ë§ì¶¤ë²• êµì •**\n\nêµì •í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ: 'ì•ˆë…•í•˜ì„¸ìš”. ì œê°€ ì˜¤ëŠ˜ íšŒì˜ì— ì°¸ì„ëª»í• ê²ƒ ê°™ìŠµë‹ˆë‹¤' êµì •í•´ì£¼ì„¸ìš”"
        
        # âœ… ì‹¤ì œ HuggingFace API ì‚¬ìš©í•œ êµì •
        hf_token = os.getenv("HF_TOKEN")
        if not hf_token:
            return f"ğŸ“ **ë¬¸ë²• êµì • ê²°ê³¼**\n\nì›ë³¸: {correction_text}\n\nâš ï¸ HF_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•„ êµì • ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            from huggingface_hub import InferenceClient
            
            client = InferenceClient(
                model="Qwen/Qwen2.5-7B-Instruct",
                token=hf_token
            )
            
            # ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ ì‘ì„±
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•, ë¬¸ë²•, ë„ì–´ì“°ê¸°ë¥¼ êµì •í•´ì£¼ì„¸ìš”. ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ í•œêµ­ì–´/ì˜ì–´ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

ì›ë³¸ í…ìŠ¤íŠ¸:
"{correction_text}"

êµì • ì§€ì¹¨:
1. ë§ì¶¤ë²• ì˜¤ë¥˜ ìˆ˜ì •
2. ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •  
3. ë„ì–´ì“°ê¸° ìˆ˜ì •
4. ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ê°œì„ 
5. ì›ë˜ ì˜ë¯¸ëŠ” ìœ ì§€

êµì •ëœ í…ìŠ¤íŠ¸:"""
            
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ êµì • í¸ì§‘ìì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë§ì¶¤ë²•, ë¬¸ë²•, ë„ì–´ì“°ê¸°ë¥¼ ì •í™•í•˜ê²Œ êµì •í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = client.chat_completion(
                messages=messages,
                max_tokens=300,
                temperature=0.3
            )
            
            corrected_text = response.choices[0].message.content.strip()
            
            # êµì • ê²°ê³¼ ë¶„ì„
            changes_made = []
            
            # ê°„ë‹¨í•œ ë³€í™” ê°ì§€
            if len(corrected_text) != len(correction_text):
                changes_made.append("ê¸¸ì´ ë³€ê²½")
            if corrected_text != correction_text:
                changes_made.append("ë‚´ìš© ìˆ˜ì •")
            
            print(f"[âœ… ì‹¤ì œ ë¬¸ë²• êµì • ì™„ë£Œ] ì›ë³¸: {len(correction_text)}ì -> êµì •: {len(corrected_text)}ì")
            
            return f"""ğŸ“ **ë¬¸ë²• ë° ë§ì¶¤ë²• êµì • ì™„ë£Œ**

**ì›ë³¸:**
{correction_text}

**êµì •ëœ í…ìŠ¤íŠ¸:**
{corrected_text}

**ë³€ê²½ì‚¬í•­:**
{', '.join(changes_made) if changes_made else 'ìˆ˜ì •í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'}

âœ… **AI êµì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**
ğŸ’¡ êµì • ê²°ê³¼ë¥¼ ê²€í† í•œ í›„ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
            
        except Exception as e:
            print(f"[â—êµì • API ì˜¤ë¥˜] {str(e)}")
            
            # âœ… ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ êµì •ìœ¼ë¡œ fallback
            simple_corrections = {
                # ìì£¼ í‹€ë¦¬ëŠ” ë§ì¶¤ë²•
                "ë°ì´íƒ€": "ë°ì´í„°",
                "ì»´í“¨íƒ€": "ì»´í“¨í„°", 
                "ì…‹íŒ…": "ì„¤ì •",
                "ë¯¸íŒ…": "íšŒì˜",
                "ì–´í”Œë¦¬ì¼€ì´ì…˜": "ì• í”Œë¦¬ì¼€ì´ì…˜",
                "ì–´í”Œ": "ì•±",
                
                # ë„ì–´ì“°ê¸°
                "ì•ˆë…•í•˜ì„¸ìš”.": "ì•ˆë…•í•˜ì„¸ìš”. ",
                "ì…ë‹ˆë‹¤.": "ì…ë‹ˆë‹¤. ",
                "í•©ë‹ˆë‹¤.": "í•©ë‹ˆë‹¤. ",
                
                # ìì£¼ í‹€ë¦¬ëŠ” í‘œí˜„
                "í•´ì•¼ë˜ëŠ”": "í•´ì•¼ í•˜ëŠ”",
                "í• ìˆ˜ìˆëŠ”": "í•  ìˆ˜ ìˆëŠ”",
                "ëª»í• ê²ƒ": "ëª»í•  ê²ƒ",
                "ì°¸ì„ëª»í• ": "ì°¸ì„í•˜ì§€ ëª»í• "
            }
            
            corrected_simple = correction_text
            applied_corrections = []
            
            for wrong, correct in simple_corrections.items():
                if wrong in corrected_simple:
                    corrected_simple = corrected_simple.replace(wrong, correct)
                    applied_corrections.append(f"'{wrong}' â†’ '{correct}'")
            
            if applied_corrections:
                return f"""ğŸ“ **ê°„ë‹¨ ë§ì¶¤ë²• êµì •**

**ì›ë³¸:**
{correction_text}

**êµì •ëœ í…ìŠ¤íŠ¸:**
{corrected_simple}

**ì ìš©ëœ êµì •:**
{chr(10).join('â€¢ ' + correction for correction in applied_corrections)}

âš ï¸ **ì°¸ê³ :** AI êµì • ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ê·œì¹™ë§Œ ì ìš©í–ˆìŠµë‹ˆë‹¤."""
            else:
                return f"""ğŸ“ **êµì • ê²€í†  ì™„ë£Œ**

**ì…ë ¥ëœ í…ìŠ¤íŠ¸:**
{correction_text}

âœ… **í˜„ì¬ í…ìŠ¤íŠ¸ì—ì„œ ëª…ë°±í•œ ì˜¤ë¥˜ë¥¼ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.**

ğŸ’¡ **ì°¸ê³ :**
â€¢ AI êµì • ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤
â€¢ ë” ì •í™•í•œ êµì •ì„ ìœ„í•´ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”
â€¢ íŠ¹ì • ë¶€ë¶„ì´ ì˜ì‹¬ìŠ¤ëŸ½ë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì í•´ì£¼ì„¸ìš”"""
            
    except Exception as e:
        print(f"[â—ë¬¸ë²• êµì • ì˜¤ë¥˜] {str(e)}")
        return "âŒ ë¬¸ë²• êµì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
# handle_image_generation í•¨ìˆ˜ë¥¼ ì´ê²ƒìœ¼ë¡œ êµì²´í•˜ì„¸ìš”

def handle_image_generation(user_input):
    """ì‹¤ì œ ì‘ë™í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ (HuggingFace API ì‚¬ìš©)"""
    try:
        # ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
        image_prompt = user_input
        
        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ì œê±°
        remove_words = ["ì´ë¯¸ì§€ ìƒì„±í•´ì£¼ì„¸ìš”", "ì´ë¯¸ì§€ ìƒì„±", "ê·¸ë ¤ì¤˜", "ê·¸ë¦¼", "image generation", "generate", "ë§Œë“¤ì–´"]
        for word in remove_words:
            image_prompt = image_prompt.replace(word, "").strip()
        
        if not image_prompt:
            return "ğŸ¨ **ì´ë¯¸ì§€ ìƒì„±**\n\nìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ:\nâ€¢ 'ì•„ë¦„ë‹¤ìš´ ì„ì–‘ê³¼ ë°”ë‹¤'\nâ€¢ 'ê·€ì—¬ìš´ ê³ ì–‘ì´ê°€ ë†€ê³  ìˆëŠ” ëª¨ìŠµ'\nâ€¢ 'A beautiful sunset over the ocean'"
        
        # âœ… ì‹¤ì œ HuggingFace ì´ë¯¸ì§€ ìƒì„± API ì‚¬ìš©
        hf_token = os.getenv("HF_TOKEN")
        if not hf_token:
            return f"ğŸ¨ **ì´ë¯¸ì§€ ìƒì„±**\n\nìš”ì²­ëœ ì´ë¯¸ì§€: '{image_prompt}'\n\nâš ï¸ HF_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ë¯¸ì§€ ìƒì„±ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            from huggingface_hub import InferenceClient
            import base64
            import time
            
            # âœ… Stable Diffusion ëª¨ë¸ ì‚¬ìš©
            client = InferenceClient(
                model="runwayml/stable-diffusion-v1-5",
                token=hf_token
            )
            
            # í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ìœ„í•´)
            korean_to_english = {
                "ê³ ì–‘ì´": "cute cat",
                "ê°•ì•„ì§€": "cute dog", 
                "ê½ƒ": "beautiful flowers",
                "ë°”ë‹¤": "ocean and waves",
                "ì‚°": "mountains and nature",
                "ì„ì–‘": "beautiful sunset",
                "í•˜ëŠ˜": "blue sky with clouds",
                "ìˆ²": "forest and trees",
                "ë„ì‹œ": "modern city",
                "ìë™ì°¨": "modern car",
                "ì§‘": "beautiful house",
                "ì‚¬ëŒ": "person",
                "ìŒì‹": "delicious food",
                "ì¼€ì´í¬": "beautiful cake"
            }
            
            # ì˜ì–´ í”„ë¡¬í”„íŠ¸ ìƒì„±
            english_prompt = image_prompt
            if any(ord(char) > 127 for char in image_prompt):  # í•œêµ­ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
                for korean, english in korean_to_english.items():
                    if korean in image_prompt:
                        english_prompt = english_prompt.replace(korean, english)
                
                # ë§¤ì¹­ë˜ì§€ ì•Šì€ í•œêµ­ì–´ê°€ ìˆìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
                if any(ord(char) > 127 for char in english_prompt):
                    english_prompt = f"a beautiful {image_prompt}"
            
            # í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ê°œì„ 
            enhanced_prompt = f"{english_prompt}, high quality, detailed, beautiful, artistic"
            
            print(f"[ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘] '{image_prompt}' -> '{enhanced_prompt}'")
            
            # âœ… ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±
            image_bytes = client.text_to_image(
                prompt=enhanced_prompt,
                height=512,
                width=512,
                num_inference_steps=20
            )
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© (ì›¹ì—ì„œ í‘œì‹œí•˜ê¸° ìœ„í•´)
            image_base64 = base64.b64encode(image_bytes).decode()
            
            # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            timestamp = int(time.time())
            filename = f"generated_image_{timestamp}.png"
            filepath = os.path.join(ATTACHMENT_FOLDER, filename)
            
            # ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
            os.makedirs(ATTACHMENT_FOLDER, exist_ok=True)
            
            with open(filepath, "wb") as f:
                f.write(image_bytes)
            
            print(f"[âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ] íŒŒì¼ ì €ì¥: {filepath}")
            
            return f"""ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!**

ğŸ“ **ìš”ì²­:** '{image_prompt}'
ğŸ–¼ï¸ **ìƒì„±ëœ ì´ë¯¸ì§€:** {filename}
ğŸ“ **ì €ì¥ ìœ„ì¹˜:** /static/attachments/{filename}
ğŸŒ **ì›¹ ì£¼ì†Œ:** http://localhost:5001/static/attachments/{filename}

âœ… **ì„±ê³µ!** ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ”— **ì´ë¯¸ì§€ ì •ë³´:**
- íŒŒì¼ëª…: {filename}
- í¬ê¸°: 512x512 í”½ì…€
- í”„ë¡¬í”„íŠ¸: "{enhanced_prompt}"
- ì €ì¥ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}

ğŸ’¡ **ì‚¬ìš© ë°©ë²•:**
1. ìœ„ ì›¹ ì£¼ì†Œë¥¼ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ ì´ë¯¸ì§€ í™•ì¸
2. íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ static/attachments í´ë” í™•ì¸
3. ë” êµ¬ì²´ì ì¸ ì„¤ëª…ìœ¼ë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥

ğŸ¯ **íŒ:** ë” êµ¬ì²´ì ì¸ ì„¤ëª…ì„ í•˜ë©´ ë” ì¢‹ì€ ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"""

        except Exception as e:
            error_msg = str(e)
            print(f"[â—ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨] {error_msg}")
            
            # âœ… êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ëŒ€ì‘
            if "rate limit" in error_msg.lower():
                return f"""ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± - ì¼ì‹œì  ì œí•œ**

ìš”ì²­ëœ ì´ë¯¸ì§€: '{image_prompt}'

â³ **ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”**
ì˜¤ë¥˜: API ìš”ì²­ í•œë„ ì´ˆê³¼

ğŸ’¡ **ëŒ€ì•ˆ:**
â€¢ 1-2ë¶„ í›„ ë‹¤ì‹œ ì‹œë„
â€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„
â€¢ ì˜ì–´ë¡œ ì…ë ¥: "{image_prompt} in English" """
                
            elif "unauthorized" in error_msg.lower() or "token" in error_msg.lower():
                return f"""ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± - ì¸ì¦ ì˜¤ë¥˜**

ìš”ì²­ëœ ì´ë¯¸ì§€: '{image_prompt}'

ğŸ”‘ **ì¸ì¦ ë¬¸ì œ ë°œìƒ**
ì˜¤ë¥˜: HuggingFace í† í° ì¸ì¦ ì‹¤íŒ¨

ğŸ’¡ **í•´ê²°ë°©ë²•:**
â€¢ ê´€ë¦¬ìì—ê²Œ HF_TOKEN í™•ì¸ ìš”ì²­
â€¢ í† í°ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"""
                
            else:
                return f"""ğŸ¨ **ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨**

ìš”ì²­ëœ ì´ë¯¸ì§€: '{image_prompt}'

âŒ **ìƒì„± ì‹¤íŒ¨**
ì˜¤ë¥˜: {error_msg}

ğŸ’¡ **ë‹¤ë¥¸ ë°©ë²• ì‹œë„:**
â€¢ ë” ê°„ë‹¨í•œ ì„¤ëª… ì‚¬ìš©: "cat", "flower", "sunset"
â€¢ ì˜ì–´ë¡œ ì…ë ¥í•´ë³´ì„¸ìš”
â€¢ íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ì¬ì‹œë„

ğŸ“ **ì˜ˆì‹œ:**
- "beautiful landscape" 
- "cute animal"
- "modern building" """
            
    except Exception as e:
        print(f"[â—ì´ë¯¸ì§€ ìƒì„± í•¸ë“¤ëŸ¬ ì˜¤ë¥˜] {str(e)}")
        return "âŒ ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
def handle_general_search(user_input, user_email, app_password):
    """ì¼ë°˜ í‚¤ì›Œë“œ ë©”ì¼ ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
    try:
        print(f"[ğŸ” ì¼ë°˜ ê²€ìƒ‰ ì‹œì‘] ì…ë ¥: '{user_input}', ì‚¬ìš©ì: {user_email}")
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ 
        search_keywords = user_input.lower()
        
        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ì œê±°
        remove_words = ["ì°¾ì•„ì¤˜", "ì°¾ì•„ì£¼ì„¸ìš”", "ê²€ìƒ‰í•´ì¤˜", "ê²€ìƒ‰", "find", "search", "ë©”ì¼", "ì´ë©”ì¼", "email"]
        for word in remove_words:
            search_keywords = search_keywords.replace(word, "").strip()
        
        print(f"[ğŸ¯ ì¶”ì¶œëœ í‚¤ì›Œë“œ] '{search_keywords}'")
        
        if not search_keywords:
            return "ğŸ” **ë©”ì¼ ê²€ìƒ‰**\n\nê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ:\nâ€¢ 'íšŒì˜ ê´€ë ¨ ë©”ì¼ ì°¾ì•„ì¤˜'\nâ€¢ 'í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ ê²€ìƒ‰'\nâ€¢ 'ê¸‰í•œ ë©”ì¼ ì°¾ê¸°'"
        
        # ì‹¤ì œ ë©”ì¼ ê²€ìƒ‰ ë¡œì§
        try:
            # ë©”ì¼ ì„œë²„ ì—°ê²°
            print("[ğŸ“§ ë©”ì¼ ì„œë²„ ì—°ê²° ì‹œì‘]")
            mail = imaplib.IMAP4_SSL("imap.gmail.com")
            mail.login(user_email, app_password)
            mail.select("inbox")
            print("[âœ… ë©”ì¼ ì„œë²„ ì—°ê²° ì„±ê³µ]")
            
            # ë” ë§ì€ ë©”ì¼ ê²€ìƒ‰ (ë²”ìœ„ í™•ëŒ€)
            N = 50  # 50ê°œë¡œ ì¦ê°€
            status, data_result = mail.search(None, "ALL")
            all_mail_ids = data_result[0].split()
            mail_ids = all_mail_ids[-N:]
            
            print(f"[ğŸ“Š ê²€ìƒ‰ ë²”ìœ„] ì´ {len(all_mail_ids)}ê°œ ì¤‘ ìµœê·¼ {len(mail_ids)}ê°œ ê²€ìƒ‰")
            
            found_emails = []
            processed_count = 0
            
            for msg_id in mail_ids:
                try:
                    _, msg_data = mail.fetch(msg_id, "(RFC822)")
                    if not msg_data or not msg_data[0]:
                        continue
                    
                    msg = email_module.message_from_bytes(msg_data[0][1])
                    processed_count += 1
                    
                    # ì œëª© ë””ì½”ë”© (ê¸°ì¡´ summary í•¨ìˆ˜ì™€ ê°™ì€ ë°©ì‹)
                    raw_subject = msg.get("Subject", "")
                    try:
                        decoded_parts = decode_header(raw_subject)
                        if decoded_parts and decoded_parts[0]:
                            decoded_subject = decoded_parts[0]
                            subject_bytes = decoded_subject[0]
                            subject_encoding = decoded_subject[1]
                            
                            if isinstance(subject_bytes, bytes):
                                if subject_encoding is None:
                                    subject_encoding = 'utf-8'
                                try:
                                    subject = subject_bytes.decode(subject_encoding)
                                except (UnicodeDecodeError, LookupError):
                                    subject = subject_bytes.decode('utf-8', errors='ignore')
                            else:
                                subject = str(subject_bytes)
                        else:
                            subject = "(ì œëª© ì—†ìŒ)"
                    except Exception as e:
                        subject = raw_subject if raw_subject else "(ì œëª© ì—†ìŒ)"
                    
                    # ë°œì‹ ì ì •ë³´
                    name, addr = parseaddr(msg.get("From"))
                    from_field = f"{name} <{addr}>" if name else addr
                    
                    # ë‚ ì§œ ì •ë³´
                    raw_date = msg.get("Date", "")
                    try:
                        date_obj = parsedate_to_datetime(raw_date)
                        date_str = date_obj.strftime("%Y-%m-%d %H:%M")
                    except:
                        date_str = raw_date[:16] if len(raw_date) >= 16 else raw_date
                    
                    # ë³¸ë¬¸ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
                    body = ""
                    try:
                        if msg.is_multipart():
                            for part in msg.walk():
                                if part.get_content_type() == "text/plain" and not part.get("Content-Disposition"):
                                    charset = part.get_content_charset() or "utf-8"
                                    body += part.get_payload(decode=True).decode(charset, errors="ignore")
                        else:
                            charset = msg.get_content_charset() or "utf-8"
                            body = msg.get_payload(decode=True).decode(charset, errors="ignore")
                        body = body.strip()[:200]  # ì²˜ìŒ 200ìë§Œ
                    except Exception as e:
                        body = ""
                    
                    # ê°œì„ ëœ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì œëª©, ë°œì‹ ì, ë³¸ë¬¸ì—ì„œ ëª¨ë‘ ê²€ìƒ‰)
                    search_in = f"{subject} {from_field} {body}".lower()
                    
                    # ì—¬ëŸ¬ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ í¬í•¨
                    keywords = search_keywords.split()
                    if any(keyword in search_in for keyword in keywords):
                        found_emails.append({
                            "subject": subject[:60] + "..." if len(subject) > 60 else subject,
                            "from": from_field[:40] + "..." if len(from_field) > 40 else from_field,
                            "date": date_str,
                            "preview": body[:100] + "..." if len(body) > 100 else body
                        })
                        
                        print(f"[âœ… ë§¤ì¹­] {subject[:30]}...")
                        
                        if len(found_emails) >= 8:  # ìµœëŒ€ 8ê°œê¹Œì§€
                            break
                            
                except Exception as e:
                    print(f"[âš ï¸ ë©”ì¼ ì²˜ë¦¬ ì˜¤ë¥˜] {str(e)}")
                    continue
            
            mail.close()
            mail.logout()
            
            print(f"[ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ] {processed_count}ê°œ ì²˜ë¦¬, {len(found_emails)}ê°œ ë°œê²¬")
            
            if found_emails:
                result = f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼**\n\ní‚¤ì›Œë“œ: '{search_keywords}'\nê²€ìƒ‰ëœ ë©”ì¼: {len(found_emails)}ê°œ (ì´ {processed_count}ê°œ ì¤‘)\n\n"
                for i, mail_info in enumerate(found_emails, 1):
                    result += f"**{i}. {mail_info['subject']}**\n"
                    result += f"ğŸ“¤ {mail_info['from']}\n"
                    result += f"ğŸ“… {mail_info['date']}\n"
                    if mail_info['preview']:
                        result += f"ğŸ’¬ {mail_info['preview']}\n"
                    result += "\n"
                result += "ğŸ’¡ ë” ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•´ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
                return result
            else:
                return f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼**\n\ní‚¤ì›Œë“œ: '{search_keywords}'\nê²€ìƒ‰ ë²”ìœ„: ìµœê·¼ {processed_count}ê°œ ë©”ì¼\n\nâŒ ê´€ë ¨ëœ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ **ê²€ìƒ‰ íŒ:**\nâ€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”\nâ€¢ ë°œì‹ ì ì´ë¦„ì´ë‚˜ íšŒì‚¬ëª… ì‚¬ìš©\nâ€¢ ë©”ì¼ ì œëª©ì˜ í•µì‹¬ ë‹¨ì–´ ì‚¬ìš©\nâ€¢ ì˜ì–´/í•œêµ­ì–´ ëª¨ë‘ ì‹œë„"
                
        except Exception as e:
            print(f"[â—ë©”ì¼ ê²€ìƒ‰ ì˜¤ë¥˜] {str(e)}")
            return f"âŒ ë©”ì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜ ë‚´ìš©: {str(e)}\n\nğŸ’¡ ë¡œê·¸ì¸ ì •ë³´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        
    except Exception as e:
        print(f"[â—ì¼ë°˜ ê²€ìƒ‰ ì˜¤ë¥˜] {str(e)}")
        return "âŒ ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def handle_person_search(user_input, user_email, app_password):
    """íŠ¹ì • ì‚¬ëŒ ë©”ì¼ ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
    try:
        print(f"[ğŸ‘¤ ì‚¬ëŒ ê²€ìƒ‰ ì‹œì‘] ì…ë ¥: '{user_input}'")
        
        # Qwenì„ ì´ìš©í•´ ì‚¬ëŒ ì´ë¦„/ì´ë©”ì¼ ì¶”ì¶œ
        search_target = extract_search_target_with_qwen(user_input)
        print(f"[ğŸ¯ ì¶”ì¶œëœ ëŒ€ìƒ] '{search_target}'")
        
        # Qwen ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ì¶”ì¶œ ë°©ë²•
        if not search_target or len(search_target.strip()) < 2:
            # ê°„ë‹¨í•œ ì´ë¦„/ì´ë©”ì¼ ì¶”ì¶œ
            words = user_input.split()
            potential_targets = []
            
            for word in words:
                # ì´ë©”ì¼ ì£¼ì†Œ íŒ¨í„´
                if "@" in word and "." in word:
                    potential_targets.append(word)
                # í•œêµ­ì–´ ì´ë¦„ íŒ¨í„´ (2-4ê¸€ì)
                elif len(word) >= 2 and len(word) <= 4 and word.replace(" ", "").isalpha():
                    potential_targets.append(word)
            
            if potential_targets:
                search_target = potential_targets[0]
            else:
                return "ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰**\n\nì°¾ê³  ì‹¶ì€ ì‚¬ëŒì˜ ì´ë¦„ì´ë‚˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ:\nâ€¢ 'ê¹€ì² ìˆ˜ë‹˜ì˜ ë©”ì¼'\nâ€¢ 'john@company.com ë©”ì¼'\nâ€¢ 'í™ê¸¸ë™ êµìˆ˜ë‹˜ ë©”ì¼'"
        
        print(f"[ğŸ” ìµœì¢… ê²€ìƒ‰ ëŒ€ìƒ] '{search_target}'")
        
        try:
            # ë©”ì¼ ì„œë²„ ì—°ê²°
            mail = imaplib.IMAP4_SSL("imap.gmail.com")
            mail.login(user_email, app_password)
            mail.select("inbox")
            
            # ë” ë§ì€ ë©”ì¼ ê²€ìƒ‰
            N = 100  # 100ê°œë¡œ ì¦ê°€
            status, data_result = mail.search(None, "ALL")
            all_mail_ids = data_result[0].split()
            mail_ids = all_mail_ids[-N:]
            
            print(f"[ğŸ“Š ê²€ìƒ‰ ë²”ìœ„] ìµœê·¼ {len(mail_ids)}ê°œ ë©”ì¼ì—ì„œ ê²€ìƒ‰")
            
            found_emails = []
            processed_count = 0
            
            for msg_id in mail_ids:
                try:
                    _, msg_data = mail.fetch(msg_id, "(RFC822)")
                    if not msg_data or not msg_data[0]:
                        continue
                    
                    msg = email_module.message_from_bytes(msg_data[0][1])
                    processed_count += 1
                    
                    # ë°œì‹ ì ì •ë³´ ì¶”ì¶œ
                    from_header = msg.get("From", "")
                    name, addr = parseaddr(from_header)
                    from_field = f"{name} <{addr}>" if name else addr
                    
                    # ì œëª© ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                    subject = str(msg.get("Subject", ""))[:80]
                    
                    # ë‚ ì§œ ì¶”ì¶œ
                    date_field = str(msg.get("Date", ""))[:25]
                    
                    # ê²€ìƒ‰ ëŒ€ìƒì´ ë°œì‹ ì ì •ë³´ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ë¶€ë¶„ ë§¤ì¹­)
                    search_lower = search_target.lower()
                    from_lower = from_field.lower()
                    
                    # ë” ê´€ëŒ€í•œ ë§¤ì¹­
                    if (search_lower in from_lower or 
                        any(part.strip() in from_lower for part in search_lower.split() if part.strip()) or
                        (len(search_lower) >= 3 and search_lower in from_lower.replace(" ", ""))):
                        
                        found_emails.append({
                            "subject": subject,
                            "from": from_field,
                            "date": date_field
                        })
                        
                        print(f"[âœ… ë§¤ì¹­] {from_field} -> {subject[:30]}...")
                        
                        if len(found_emails) >= 10:  # ìµœëŒ€ 10ê°œê¹Œì§€
                            break
                            
                except Exception as e:
                    continue
            
            mail.close()
            mail.logout()
            
            print(f"[ğŸ“Š ì‚¬ëŒ ê²€ìƒ‰ ì™„ë£Œ] {processed_count}ê°œ ì²˜ë¦¬, {len(found_emails)}ê°œ ë°œê²¬")
            
            if found_emails:
                result = f"ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼**\n\nê²€ìƒ‰ ëŒ€ìƒ: '{search_target}'\në°œê²¬ëœ ë©”ì¼: {len(found_emails)}ê°œ (ì´ {processed_count}ê°œ ì¤‘)\n\n"
                for i, mail_info in enumerate(found_emails, 1):
                    result += f"**{i}. {mail_info['subject']}**\n"
                    result += f"ğŸ“¤ {mail_info['from']}\n"
                    result += f"ğŸ“… {mail_info['date']}\n\n"
                result += "ğŸ’¡ íŠ¹ì • ë©”ì¼ì„ ìì„¸íˆ ë³´ë ¤ë©´ ë©”ì¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”."
                return result
            else:
                return f"ğŸ‘¤ **ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ê²°ê³¼**\n\nê²€ìƒ‰ ëŒ€ìƒ: '{search_target}'\nê²€ìƒ‰ ë²”ìœ„: ìµœê·¼ {processed_count}ê°œ ë©”ì¼\n\nâŒ í•´ë‹¹ ì‚¬ëŒì˜ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ’¡ **ê²€ìƒ‰ íŒ:**\nâ€¢ ì •í™•í•œ ì´ë¦„ ì‚¬ìš©: '{search_target}' â†’ ë‹¤ë¥¸ í‘œê¸°ë²• ì‹œë„\nâ€¢ ì´ë©”ì¼ ì£¼ì†Œë¡œ ì‹œë„\nâ€¢ ì„±ì´ë‚˜ ì´ë¦„ë§Œìœ¼ë¡œ ì‹œë„\nâ€¢ ì˜ë¬¸/í•œê¸€ ì´ë¦„ ëª¨ë‘ ì‹œë„"
                
        except Exception as e:
            print(f"[â—ì‚¬ëŒ ê²€ìƒ‰ ì˜¤ë¥˜] {str(e)}")
            return f"âŒ ì‚¬ëŒë³„ ë©”ì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {str(e)}"
        
    except Exception as e:
        print(f"[â—ì‚¬ëŒ ê²€ìƒ‰ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜] {str(e)}")
        return "âŒ ì‚¬ëŒ ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route('/api/test', methods=['POST'])
def test():
    data = request.get_json()
    text = data.get("text", "")
    email = data.get("email", "")
    
    user_key = get_user_key(email) if email else "anonymous"
    
    return jsonify({
        "message": f"âœ… ë°±ì—”ë“œ ì •ìƒ ì‘ë™: {text[:20]}...",
        "user_session": user_key[:8] + "..." if email else "no_session"
    })

@app.route("/api/send", methods=["POST"])
def send_email():
    try:
        data = request.get_json()
        print("âœ… ë°›ì€ ë°ì´í„°:", data)

        sender_email = data["email"]
        app_password = data["app_password"]
        to = data["to"]
        subject = data["subject"]
        body = data["body"]

        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(sender_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401

        msg = MIMEText(body)
        msg["Subject"] = subject
        msg["From"] = sender_email
        msg["To"] = to

        server = smtplib.SMTP_SSL("smtp.gmail.com", 465)
        server.login(sender_email, app_password)
        server.send_message(msg)
        server.quit()

        print(f"[ğŸ“¤ ë©”ì¼ ì „ì†¡ ì„±ê³µ] ì‚¬ìš©ì: {sender_email}, ìˆ˜ì‹ ì: {to}")

        return jsonify({"message": "âœ… ë©”ì¼ ì „ì†¡ ì„±ê³µ"}), 200

    except Exception as e:
        print("[â—ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨]", str(e))
        return jsonify({"error": str(e)}), 500

@app.route('/api/session-info', methods=['GET'])
def session_info():
    """í˜„ì¬ í™œì„± ì„¸ì…˜ ì •ë³´ ë°˜í™˜ (ë””ë²„ê·¸ìš©)"""
    return jsonify({
        "active_sessions": len(user_sessions),
        "session_keys": [key[:8] + "..." for key in user_sessions.keys()],
        "yolo_model_loaded": yolo_model is not None
    })

@app.route('/', methods=['GET'])
def health_check():
    return "âœ… ë°±ì—”ë“œ ì •ìƒ ì‘ë™ ì¤‘ (ì‚¬ìš©ì ì„¸ì…˜ ë¶„ë¦¬ ì ìš©)\n{yolo_status}", 200

# âœ… ìƒˆë¡œìš´ ì²¨ë¶€íŒŒì¼ ì •ë³´ API ì¶”ê°€
@app.route('/api/attachment-info', methods=['POST'])
def attachment_info():
    """íŠ¹ì • ë©”ì¼ì˜ ì²¨ë¶€íŒŒì¼ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
    try:
        data = request.get_json()
        email_id = data.get("email_id")
        user_email = data.get("email", "")
        
        # ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
        user_key = get_user_key(user_email)
        if user_key not in user_sessions:
            return jsonify({"error": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 401
        
        # ì„¸ì…˜ì—ì„œ í•´ë‹¹ ë©”ì¼ ì°¾ê¸°
        last_emails = user_sessions[user_key].get('last_emails', [])
        target_email = None
        
        for email_data in last_emails:
            if email_data.get('id') == email_id:
                target_email = email_data
                break
        
        if not target_email:
            return jsonify({"error": "í•´ë‹¹ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        attachments = target_email.get('attachments', [])
        
        return jsonify({
            "success": True,
            "email_id": email_id,
            "subject": target_email.get('subject', ''),
            "attachments": attachments,
            "attachment_count": len(attachments),
            "has_yolo_detections": any(att.get('yolo_detections') for att in attachments)
        })
        
    except Exception as e:
        print(f"[â—ì²¨ë¶€íŒŒì¼ ì •ë³´ ì˜¤ë¥˜] {str(e)}")
        return jsonify({"error": str(e)}), 500


# to ëŒ€ì‰¬ë³´ë“œìš© ì¶”ê°€ ì½”ë“œ

# í• ì¼ ì¶”ì¶œì„ ìœ„í•œ í‚¤ì›Œë“œ íŒ¨í„´ë“¤
TODO_KEYWORDS = {
    'meeting': ['íšŒì˜', 'ë¯¸íŒ…', 'meeting', 'ì»¨í¼ëŸ°ìŠ¤', 'ì„¸ë¯¸ë‚˜', 'ë©´ë‹´', 'ìƒë‹´'],
    'deadline': ['ë§ˆê°', 'ì œì¶œ', 'ì™„ë£Œ', 'ëë‚´', 'deadline', 'due', 'ê¸°í•œ', 'ê¹Œì§€'],
    'task': ['ì‘ì—…', 'ì—…ë¬´', 'ì²˜ë¦¬', 'ì§„í–‰', 'í•´ì•¼', 'í• ê²ƒ', 'task', 'work', 'todo'],
    'event': ['í–‰ì‚¬', 'ì´ë²¤íŠ¸', 'event', 'íŒŒí‹°', 'ëª¨ì„', 'ì•½ì†', 'ì¼ì •'],
    'reminder': ['ì•Œë¦¼', 'reminder', 'ìŠì§€ë§', 'ê¸°ì–µ', 'ì²´í¬', 'í™•ì¸']
}

# ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ íŒ¨í„´
DATE_PATTERNS = [
    r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',  # 2024ë…„ 12ì›” 25ì¼
    r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',              # 12ì›” 25ì¼
    r'(\d{1,2})/(\d{1,2})',                    # 12/25
    r'(\d{4}-\d{1,2}-\d{1,2})',               # 2024-12-25
    r'(ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ)',                        # ìƒëŒ€ì  ë‚ ì§œ
    r'(ë‹¤ìŒì£¼|ì´ë²ˆì£¼|ë‹¤ë‹¤ìŒì£¼)',                 # ìƒëŒ€ì  ì£¼
    r'(ì›”ìš”ì¼|í™”ìš”ì¼|ìˆ˜ìš”ì¼|ëª©ìš”ì¼|ê¸ˆìš”ì¼|í† ìš”ì¼|ì¼ìš”ì¼)'  # ìš”ì¼
]

TIME_PATTERNS = [
    r'(\d{1,2}):(\d{2})',                      # 14:30
    r'(\d{1,2})ì‹œ\s*(\d{1,2})?ë¶„?',           # 2ì‹œ 30ë¶„
    r'(ì˜¤ì „|ì˜¤í›„)\s*(\d{1,2})ì‹œ',              # ì˜¤ì „ 10ì‹œ
]

def extract_todos_from_email_improved(email_body, email_subject, email_from, email_date):
    """ê°œì„ ëœ ì´ë©”ì¼ í• ì¼ ì¶”ì¶œ í•¨ìˆ˜ - ê³ ìœ  ID ì¶”ê°€"""
    try:
        print(f"[ğŸ“‹ ê°œì„ ëœ í• ì¼ ì¶”ì¶œ] {email_subject[:30]}...")
        
        full_text = f"{email_subject} {email_body}"
        todos = []
        
        # âœ… ê³ ìœ  ID ìƒì„±ì„ ìœ„í•œ ê¸°ì¤€ ì‹œê°„
        import time
        base_timestamp = int(time.time() * 1000)
        
        # 1. íšŒì˜/ë¯¸íŒ… ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ
        try:
            meeting_todos = extract_meetings_improved(full_text, email_from, email_date, email_subject, base_timestamp)
            todos.extend(meeting_todos)
        except Exception as e:
            print(f"[âš ï¸ íšŒì˜ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")

        # 2. ë§ˆê°ì¼/ë°ë“œë¼ì¸ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ  
        deadline_todos = extract_deadlines_improved(full_text, email_from, email_date, email_subject, base_timestamp + 100)
        todos.extend(deadline_todos)
        
        # 3. ì¼ë°˜ í• ì¼ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ
        task_todos = extract_general_tasks_improved(full_text, email_from, email_date, email_subject, base_timestamp + 200)
        todos.extend(task_todos)
        
        # 4. ì´ë²¤íŠ¸/í–‰ì‚¬ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ
        event_todos = extract_events_improved(full_text, email_from, email_date, email_subject, base_timestamp + 300)
        todos.extend(event_todos)
        
        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì„¤ì •
        todos = deduplicate_todos_improved(todos)
        todos = assign_priority(todos)
        
        print(f"[âœ… ê°œì„ ëœ í• ì¼ ì¶”ì¶œ ì™„ë£Œ] {len(todos)}ê°œ ë°œê²¬")
        
        return {
            'success': True,
            'todos': todos,
            'total_count': len(todos),
            'extraction_method': 'improved_ai_analysis'
        }
        
    except Exception as e:
        print(f"[â—í• ì¼ ì¶”ì¶œ ì˜¤ë¥˜] {str(e)}")
        return {
            'success': False,
            'todos': [],
            'error': str(e)
        }
    
# ì´ í•¨ìˆ˜ë¥¼ extract_deadlines_improved í•¨ìˆ˜ ë°”ë¡œ ìœ„ì— ì¶”ê°€í•˜ì„¸ìš”
def extract_meetings_improved(text, sender, email_date, email_subject, base_id):
    """ê°œì„ ëœ íšŒì˜/ë¯¸íŒ… ì¶”ì¶œ - ê³ ìœ  ID ì¶”ê°€"""
    meetings = []
    
    meeting_keywords = ['íšŒì˜', 'ë¯¸íŒ…', 'meeting', 'ë©´ë‹´', 'ìƒë‹´', 'ì»¨í¼ëŸ°ìŠ¤', 'ì„¸ë¯¸ë‚˜']
    
    for keyword in meeting_keywords:
        if keyword.lower() in text.lower():
            meeting_title = generate_smart_title(text, keyword, email_subject, 'meeting')
            meeting_date = extract_smart_date(text) or '2024-12-27'
            meeting_time = extract_smart_time(text) or '14:00'
            
            meeting = {
                'id': base_id + len(meetings),  # âœ… ê³ ìœ  ID
                'type': 'meeting',
                'title': meeting_title,
                'description': f"{sender}ë‹˜ê³¼ì˜ {keyword}",
                'date': meeting_date,
                'time': meeting_time,
                'priority': 'high',
                'status': 'pending',
                'editable_date': True,  # âœ… ë‚ ì§œ í¸ì§‘ ê°€ëŠ¥
                'source_email': {
                    'from': sender,
                    'subject': email_subject,
                    'date': email_date,
                    'type': 'meeting_invitation'
                }
            }
            meetings.append(meeting)
            print(f"[ğŸ¤ íšŒì˜ ì¶”ì¶œ] {meeting_title} (ID: {meeting['id']})")
            break
    
    return meetings

def extract_deadlines_improved(text, sender, email_date, email_subject, base_id):
    """ê°œì„ ëœ ë§ˆê°ì¼ ì¶”ì¶œ - ê³ ìœ  ID ì¶”ê°€"""
    deadlines = []
    
    deadline_keywords = ['ë§ˆê°', 'ì œì¶œ', 'ì™„ë£Œ', 'deadline', 'due', 'ê¸°í•œ', 'ê¹Œì§€', 'submit']
    
    for keyword in deadline_keywords:
        if keyword.lower() in text.lower():
            deadline_title = generate_smart_title(text, keyword, email_subject, 'deadline')
            deadline_date = extract_smart_date(text) or '2024-12-28'
            
            deadline = {
                'id': base_id + len(deadlines),  # âœ… ê³ ìœ  ID
                'type': 'deadline',
                'title': deadline_title,
                'description': f"{sender}ë‹˜ì´ ìš”ì²­í•œ ë§ˆê° ì—…ë¬´",
                'date': deadline_date,
                'time': None,
                'priority': 'high',
                'status': 'pending',
                'editable_date': True,  # âœ… ë‚ ì§œ í¸ì§‘ ê°€ëŠ¥
                'source_email': {
                    'from': sender,
                    'subject': email_subject,
                    'date': email_date,
                    'type': 'deadline_notice'
                }
            }
            deadlines.append(deadline)
            print(f"[â° ë§ˆê°ì¼ ì¶”ì¶œ] {deadline_title} (ID: {deadline['id']})")
            break
    
    return deadlines

def extract_general_tasks_improved(text, sender, email_date, email_subject, base_id):
    """ê°œì„ ëœ ì¼ë°˜ ì—…ë¬´ ì¶”ì¶œ - ê³ ìœ  ID ì¶”ê°€"""
    tasks = []
    
    task_patterns = [
        (r'([^\n\.]{10,80})\s*(í•´ì£¼ì„¸ìš”|í•´ì£¼ì‹œê¸°|ë¶€íƒë“œë¦½ë‹ˆë‹¤|ìš”ì²­ë“œë¦½ë‹ˆë‹¤)', 'korean_request'),
        (r'([^\n\.]{10,80})\s*(í™•ì¸|ê²€í† |ì²˜ë¦¬|ì§„í–‰)\s*(í•´ì£¼ì„¸ìš”|ë¶€íƒ|í•„ìš”)', 'korean_action'),
        (r'(please|kindly)\s+([^\n\.]{10,80})', 'english_request'),
        (r'([^\n\.]{10,80})\s+(please|kindly)', 'english_request_after'),
        (r'(could you|can you|would you)\s+([^\n\.]{10,80})', 'english_question'),
    ]
    
    for pattern, pattern_type in task_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            if pattern_type == 'english_request':
                task_name = match.group(2).strip()
            elif pattern_type == 'english_request_after':
                task_name = match.group(1).strip()
            elif pattern_type == 'english_question':
                task_name = match.group(2).strip()
            else:
                task_name = match.group(1).strip()
            
            if len(task_name) > 10 and not is_meaningless_text(task_name):
                clean_title = clean_task_title(task_name)
                
                task = {
                    'id': base_id + len(tasks),  # âœ… ê³ ìœ  ID
                    'type': 'task',
                    'title': clean_title,
                    'description': f"{sender}ë‹˜ì´ ìš”ì²­í•œ ì—…ë¬´",
                    'date': None,
                    'time': None,
                    'priority': 'medium',
                    'status': 'pending',
                    'editable_date': True,  # âœ… ë‚ ì§œ í¸ì§‘ ê°€ëŠ¥
                    'source_email': {
                        'from': sender,
                        'subject': email_subject,
                        'date': email_date,
                        'type': 'task_request'
                    }
                }
                tasks.append(task)
                print(f"[ğŸ“‹ ì—…ë¬´ ì¶”ì¶œ] {clean_title} (ID: {task['id']})")
                
                if len(tasks) >= 3:
                    break
    
    return tasks

def extract_events_improved(text, sender, email_date, email_subject, base_id):
    """ê°œì„ ëœ ì´ë²¤íŠ¸ ì¶”ì¶œ - ê³ ìœ  ID ì¶”ê°€"""
    events = []
    
    event_keywords = ['í–‰ì‚¬', 'ì´ë²¤íŠ¸', 'event', 'íŒŒí‹°', 'ëª¨ì„', 'ì„¸ë¯¸ë‚˜', 'ì›Œí¬ìƒµ', 'workshop']
    
    for keyword in event_keywords:
        if keyword.lower() in text.lower():
            event_title = generate_smart_title(text, keyword, email_subject, 'event')
            
            event = {
                'id': base_id + len(events),  # âœ… ê³ ìœ  ID
                'type': 'event',
                'title': event_title,
                'description': f"{sender}ë‹˜ì´ ì•Œë¦° {keyword}",
                'date': extract_smart_date(text) or '2024-12-29',
                'time': extract_smart_time(text) or '18:00',
                'priority': 'medium',
                'status': 'pending',
                'editable_date': True,  # âœ… ë‚ ì§œ í¸ì§‘ ê°€ëŠ¥
                'source_email': {
                    'from': sender,
                    'subject': email_subject,
                    'date': email_date,
                    'type': 'event_notification'
                }
            }
            events.append(event)
            print(f"[ğŸ‰ ì´ë²¤íŠ¸ ì¶”ì¶œ] {event_title} (ID: {event['id']})")
            break
    
    return events

def generate_smart_title(text, keyword, email_subject, todo_type):
    """ìŠ¤ë§ˆíŠ¸í•œ ì œëª© ìƒì„±"""
    
    # 1. ì´ë©”ì¼ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ë¶€ë¶„ ì°¾ê¸°
    subject_words = email_subject.split()
    
    # 2. ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œëª© ì‚¬ìš©
    if keyword.lower() in email_subject.lower():
        return email_subject[:60]
    
    # 3. ë³¸ë¬¸ì—ì„œ í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ì¥ ì°¾ê¸°
    sentences = text.split('.')
    for sentence in sentences:
        if keyword.lower() in sentence.lower() and len(sentence.strip()) > 10:
            clean_sentence = sentence.strip()
            if len(clean_sentence) > 60:
                clean_sentence = clean_sentence[:60] + "..."
            return clean_sentence
    
    # 4. ê¸°ë³¸ ì œëª© ìƒì„±
    type_names = {
        'meeting': 'íšŒì˜',
        'deadline': 'ë§ˆê°ì¼',
        'task': 'ì—…ë¬´',
        'event': 'ì´ë²¤íŠ¸'
    }
    
    base_name = type_names.get(todo_type, 'í• ì¼')
    return f"{base_name}: {email_subject[:40]}"

def extract_smart_date(text):
    """ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ì¶”ì¶œ"""
    
    # í•œêµ­ì–´ ë‚ ì§œ íŒ¨í„´ë“¤
    korean_patterns = [
        r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',
        r'(\d{1,2})/(\d{1,2})',
    ]
    
    for pattern in korean_patterns:
        match = re.search(pattern, text)
        if match:
            try:
                if len(match.groups()) == 3:  # ë…„ì›”ì¼
                    year, month, day = match.groups()
                    return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                elif len(match.groups()) == 2:  # ì›”ì¼
                    month, day = match.groups()
                    year = datetime.now().year
                    return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
            except:
                continue
    
    # ìƒëŒ€ì  ë‚ ì§œ
    today = datetime.now()
    if 'ì˜¤ëŠ˜' in text:
        return today.strftime('%Y-%m-%d')
    elif 'ë‚´ì¼' in text:
        return (today + timedelta(days=1)).strftime('%Y-%m-%d')
    elif 'ë‹¤ìŒì£¼' in text:
        return (today + timedelta(days=7)).strftime('%Y-%m-%d')
    
    return None

def extract_smart_time(text):
    """ìŠ¤ë§ˆíŠ¸ ì‹œê°„ ì¶”ì¶œ"""
    
    # ì‹œê°„ íŒ¨í„´ë“¤
    time_patterns = [
        r'(\d{1,2}):(\d{2})',  # 14:30
        r'ì˜¤ì „\s*(\d{1,2})ì‹œ',  # ì˜¤ì „ 10ì‹œ
        r'ì˜¤í›„\s*(\d{1,2})ì‹œ',  # ì˜¤í›„ 2ì‹œ
        r'(\d{1,2})ì‹œ\s*(\d{1,2})?ë¶„?',  # 2ì‹œ 30ë¶„
    ]
    
    for pattern in time_patterns:
        match = re.search(pattern, text)
        if match:
            if 'ì˜¤ì „' in pattern:
                hour = int(match.group(1))
                return f"{hour:02d}:00"
            elif 'ì˜¤í›„' in pattern:
                hour = int(match.group(1))
                if hour != 12:
                    hour += 12
                return f"{hour:02d}:00"
            elif ':' in match.group(0):
                return match.group(0)
            else:
                hour = int(match.group(1))
                minute = match.group(2) if len(match.groups()) > 1 and match.group(2) else "00"
                return f"{hour:02d}:{minute.zfill(2)}"
    
    return None

def is_meaningless_text(text):
    """ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    meaningless_patterns = [
        r'^[^a-zA-Zê°€-í£]*$',  # ë¬¸ìê°€ ì—†ìŒ
        r'^(please|kindly|í™•ì¸|ê²€í† |ì²˜ë¦¬)$',  # ë‹¨ì¼ í‚¤ì›Œë“œë§Œ
        r'^.{1,5}$',  # ë„ˆë¬´ ì§§ìŒ
    ]
    
    for pattern in meaningless_patterns:
        if re.match(pattern, text.strip(), re.IGNORECASE):
            return True
    
    return False

def clean_task_title(title):
    """í• ì¼ ì œëª© ì •ë¦¬"""
    
    # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ì œê±°
    remove_words = ['í•´ì£¼ì„¸ìš”', 'ë¶€íƒë“œë¦½ë‹ˆë‹¤', 'ìš”ì²­ë“œë¦½ë‹ˆë‹¤', 'please', 'kindly']
    
    clean_title = title
    for word in remove_words:
        clean_title = clean_title.replace(word, '').strip()
    
    # ì²« ê¸€ì ëŒ€ë¬¸ì ì²˜ë¦¬ (ì˜ì–´ì¸ ê²½ìš°)
    if clean_title and clean_title[0].isalpha():
        clean_title = clean_title[0].upper() + clean_title[1:]
    
    # ê¸¸ì´ ì œí•œ
    if len(clean_title) > 60:
        clean_title = clean_title[:60] + "..."
    
    return clean_title

def extract_dates_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
    dates = []
    
    for pattern in DATE_PATTERNS:
        matches = re.finditer(pattern, text)
        for match in matches:
            try:
                date_str = match.group(0)
                parsed_date = parse_korean_date(date_str)
                
                if parsed_date:
                    dates.append({
                        'original_text': date_str,
                        'parsed_date': parsed_date.isoformat(),
                        'confidence': 0.8
                    })
            except Exception as e:
                continue
    
    return dates

def extract_times_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ ì¶”ì¶œ"""  
    times = []
    
    for pattern in TIME_PATTERNS:
        matches = re.finditer(pattern, text)
        for match in matches:
            try:
                time_str = match.group(0)
                parsed_time = parse_korean_time(time_str)
                
                if parsed_time:
                    times.append({
                        'original_text': time_str,
                        'parsed_time': parsed_time,
                        'confidence': 0.8
                    })
            except Exception as e:
                continue
    
    return times

def parse_korean_date(date_str):
    """í•œêµ­ì–´ ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜"""
    try:
        # ìƒëŒ€ì  ë‚ ì§œ ì²˜ë¦¬
        today = datetime.now()
        
        if 'ì˜¤ëŠ˜' in date_str:
            return today
        elif 'ë‚´ì¼' in date_str:
            return today + timedelta(days=1)
        elif 'ëª¨ë ˆ' in date_str:
            return today + timedelta(days=2)
        elif 'ë‹¤ìŒì£¼' in date_str:
            return today + timedelta(days=7)
        
        # ìˆ«ì ë‚ ì§œ ì²˜ë¦¬
        korean_date_match = re.search(r'(\d{4})?ë…„?\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', date_str)
        if korean_date_match:
            year = korean_date_match.group(1) or today.year
            month = int(korean_date_match.group(2))
            day = int(korean_date_match.group(3))
            return datetime(int(year), month, day)
        
        # ë‹¤ë¥¸ í˜•ì‹ë“¤ë„ ì‹œë„
        return dateutil.parser.parse(date_str, fuzzy=True)
        
    except Exception as e:
        return None

def parse_korean_time(time_str):
    """í•œêµ­ì–´ ì‹œê°„ ë¬¸ìì—´ íŒŒì‹±"""
    try:
        # ì˜¤ì „/ì˜¤í›„ ì²˜ë¦¬
        if 'ì˜¤ì „' in time_str:
            hour_match = re.search(r'(\d{1,2})ì‹œ', time_str)
            if hour_match:
                hour = int(hour_match.group(1))
                return f"{hour:02d}:00"
        
        elif 'ì˜¤í›„' in time_str:
            hour_match = re.search(r'(\d{1,2})ì‹œ', time_str)
            if hour_match:
                hour = int(hour_match.group(1))
                if hour != 12:
                    hour += 12
                return f"{hour:02d}:00"
        
        # 24ì‹œê°„ í˜•ì‹
        time_match = re.search(r'(\d{1,2}):(\d{2})', time_str)
        if time_match:
            return f"{int(time_match.group(1)):02d}:{time_match.group(2)}"
        
        return None
        
    except Exception as e:
        return None

def deduplicate_todos_improved(todos):
    """ê°œì„ ëœ ì¤‘ë³µ ì œê±° - ID ê¸°ë°˜"""
    seen_titles = set()
    unique_todos = []
    
    for todo in todos:
        title_key = todo['title'].lower()
        if title_key not in seen_titles:
            seen_titles.add(title_key)
            unique_todos.append(todo)
        else:
            print(f"[ğŸ—‘ï¸ ì¤‘ë³µ ì œê±°] {todo['title']}")
    
    return unique_todos

def assign_priority(todos):
    """ìš°ì„ ìˆœìœ„ ìë™ ì„¤ì •"""
    for todo in todos:
        # í‚¤ì›Œë“œ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
        if todo['type'] == 'deadline':
            todo['priority'] = 'high'
        elif todo['type'] == 'meeting':
            todo['priority'] = 'high'
        elif 'ê¸´ê¸‰' in todo['title'] or 'urgent' in todo['title'].lower():
            todo['priority'] = 'high'
        elif todo['type'] == 'event':
            todo['priority'] = 'medium'
        else:
            todo['priority'] = 'low'
        
        # ë‚ ì§œ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¡°ì •
        if todo['date']:
            try:
                todo_date = datetime.fromisoformat(todo['date'].replace('Z', '+00:00')).replace(tzinfo=None)
                days_until = (todo_date - datetime.now()).days
                
                if days_until <= 1:  # ì˜¤ëŠ˜/ë‚´ì¼
                    todo['priority'] = 'high'
                elif days_until <= 3:  # 3ì¼ ì´ë‚´
                    if todo['priority'] == 'low':
                        todo['priority'] = 'medium'
            except:
                pass
    
    return todos
    
# âœ… ìºì‹œ ì´ˆê¸°í™” API ì¶”ê°€
@app.route('/api/clear-cache', methods=['POST'])
def clear_attachment_cache():
    """ì²¨ë¶€íŒŒì¼ ìºì‹œ ì´ˆê¸°í™”"""
    global attachment_cache
    cache_count = len(attachment_cache)
    attachment_cache.clear()
    
    return jsonify({
        "success": True,
        "message": f"ìºì‹œ {cache_count}ê°œ í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "cleared_items": cache_count
    })  

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸš€ YOLOv8 í†µí•© ë©”ì¼ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    
    # YOLO ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”© (ì„ íƒì )
    print("[ğŸ”„ YOLO ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹œë„...]")
    load_yolo_model()
    
    print("=" * 60)
    app.run(debug=True, host="0.0.0.0", port=5001)
