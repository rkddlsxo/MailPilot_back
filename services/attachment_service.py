# services/attachment_service.py - Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ ÏÑúÎπÑÏä§

import os
import io
import tempfile
import hashlib
from pathlib import Path
import numpy as np

# ÏÑ†ÌÉùÏ†Å ÏûÑÌè¨Ìä∏ - ÏóÜÎäî ÎùºÏù¥Î∏åÎü¨Î¶¨Îäî ÎπÑÌôúÏÑ±Ìôî
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("[‚ö†Ô∏è PIL/Pillow ÏóÜÏùå - Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False
    print("[‚ö†Ô∏è pdfplumber ÏóÜÏùå - PDF Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    import PyPDF2
    PYPDF2_AVAILABLE = True
except ImportError:
    PYPDF2_AVAILABLE = False
    print("[‚ö†Ô∏è PyPDF2 ÏóÜÏùå - PDF Î∞±ÏóÖ Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("[‚ö†Ô∏è python-docx ÏóÜÏùå - Word Î¨∏ÏÑú Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    from pptx import Presentation
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False
    print("[‚ö†Ô∏è python-pptx ÏóÜÏùå - PowerPoint Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("[‚ö†Ô∏è pandas ÏóÜÏùå - Excel Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

try:
    from pdf2image import convert_from_bytes
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    print("[‚ö†Ô∏è pdf2image ÏóÜÏùå - PDF OCR Ï≤òÎ¶¨ ÎπÑÌôúÏÑ±Ìôî]")

class AttachmentService:
    def __init__(self, config, ai_models):
        self.config = config
        self.ai_models = ai_models
        self.attachment_cache = {}
        
        # ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Í∏∞Îä• Ï≤¥ÌÅ¨
        self.features = {
            'image_processing': PIL_AVAILABLE,
            'pdf_processing': PDFPLUMBER_AVAILABLE or PYPDF2_AVAILABLE,
            'docx_processing': DOCX_AVAILABLE,
            'pptx_processing': PPTX_AVAILABLE,
            'xlsx_processing': PANDAS_AVAILABLE,
            'pdf_ocr': PDF2IMAGE_AVAILABLE,
            'yolo': hasattr(ai_models, 'yolo_available') and ai_models.yolo_available,
            'ocr': hasattr(ai_models, 'ocr_available') and ai_models.ocr_available
        }
        
        print(f"[üìé Ï≤®Î∂ÄÌååÏùº ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî] ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Í∏∞Îä•: {sum(self.features.values())}/{len(self.features)}")
    
    def process_email_attachments(self, email_message, email_subject, email_id):
        """Ïù¥Î©îÏùºÏóêÏÑú Ï≤®Î∂ÄÌååÏùºÏùÑ Ï∂îÏ∂úÌïòÍ≥† Ï≤òÎ¶¨ (Ï∫êÏã± Ìè¨Ìï®)"""
        cache_key = f"email_{email_id}"
        
        # Ï∫êÏãú ÌôïÏù∏
        if cache_key in self.attachment_cache:
            print(f"[üìé Ï∫êÏãú ÏÇ¨Ïö©] {email_subject[:30]}...")
            return self.attachment_cache[cache_key]
        
        attachments = []
        print(f"[üìé ÏÉàÎ°úÏö¥ Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨] {email_subject[:30]}...")
        
        try:
            for part in email_message.walk():
                if part.get_content_disposition() == 'attachment':
                    attachment_info = self._process_single_attachment(part, email_subject)
                    if attachment_info:
                        attachments.append(attachment_info)
        except Exception as e:
            print(f"[‚ùóÏ≤®Î∂ÄÌååÏùº ÏõåÌÇπ Ïò§Î•ò] {str(e)}")
        
        # Ï∫êÏãú Ï†ÄÏû•
        self.attachment_cache[cache_key] = attachments
        self._manage_cache_size()
        
        print(f"[‚úÖ Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ ÏôÑÎ£å] {len(attachments)}Í∞ú Ï≤òÎ¶¨Îê®")
        return attachments
    
    def _process_single_attachment(self, part, email_subject):
        """Í∞úÎ≥Ñ Ï≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨"""
        try:
            filename = self._decode_filename(part.get_filename())
            if not filename:
                return None
            
            attachment_data = part.get_payload(decode=True)
            if not attachment_data:
                return None
            
            file_ext = Path(filename).suffix.lower()
            mime_type = part.get_content_type()
            
            attachment_info = {
                'filename': filename,
                'size': len(attachment_data),
                'mime_type': mime_type,
                'extension': file_ext
            }
            
            # ÌååÏùº ÌÉÄÏûÖÎ≥Ñ Ï≤òÎ¶¨
            if file_ext in {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}:
                attachment_info.update(self._process_image(attachment_data, filename))
            elif file_ext == '.pdf' or 'pdf' in mime_type:
                attachment_info.update(self._process_pdf(attachment_data, filename))
            elif file_ext == '.docx' or 'wordprocessingml' in mime_type:
                attachment_info.update(self._process_docx(attachment_data, filename))
            elif file_ext == '.pptx' or 'presentationml' in mime_type:
                attachment_info.update(self._process_pptx(attachment_data, filename))
            elif file_ext in ['.xlsx', '.xls'] or 'spreadsheetml' in mime_type:
                attachment_info.update(self._process_xlsx(attachment_data, filename))
            else:
                attachment_info.update({'type': 'other', 'processing_method': 'metadata_only'})
            
            return attachment_info
            
        except Exception as e:
            print(f"[‚ùóÏ≤®Î∂ÄÌååÏùº Ï≤òÎ¶¨ Ïò§Î•ò] {filename if 'filename' in locals() else 'Unknown'}: {str(e)}")
            return None
    
    def _decode_filename(self, filename):
        """ÌååÏùºÎ™Ö ÎîîÏΩîÎî©"""
        if not filename:
            return None
        
        try:
            from email.header import decode_header
            decoded_parts = decode_header(filename)
            if decoded_parts and decoded_parts[0]:
                decoded_filename = decoded_parts[0]
                if isinstance(decoded_filename[0], bytes):
                    return decoded_filename[0].decode(decoded_filename[1] or 'utf-8')
                else:
                    return decoded_filename[0]
        except:
            pass
        
        return filename
    
    def _process_image(self, attachment_data, filename):
        """Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ (YOLO + OCR)"""
        try:
            if not PIL_AVAILABLE:
                return {'type': 'image', 'error': 'PIL not available', 'processing_method': 'disabled'}
            
            # YOLO Í∞ùÏ≤¥ Ïù∏Ïãù
            yolo_detections = []
            if self.features['yolo'] and self.ai_models.load_yolo_model():
                yolo_detections = self._yolo_detect_objects(attachment_data)
            
            # OCR ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
            ocr_result = {'text': '', 'success': False}
            if self.features['ocr'] and self.ai_models.load_ocr_model():
                ocr_result = self._extract_text_with_ocr(attachment_data, filename)
            
            result = {
                'type': 'image',
                'yolo_detections': yolo_detections,
                'detected_objects': [det['class'] for det in yolo_detections],
                'object_count': len(yolo_detections),
                'extracted_text': ocr_result.get('text', ''),
                'ocr_success': ocr_result.get('success', False),
                'processing_method': f"YOLO({len(yolo_detections)}) + OCR({ocr_result.get('success', False)})"
            }
            
            # ÌÖçÏä§Ìä∏ ÏöîÏïΩ ÏÉùÏÑ±
            if ocr_result.get('success') and ocr_result.get('text'):
                result['text_summary'] = self._summarize_document(
                    ocr_result['text'], filename, 'image_with_text'
                )
            
            return result
            
        except Exception as e:
            print(f"[‚ùóÏù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ïò§Î•ò] {str(e)}")
            return {'type': 'image', 'error': str(e), 'processing_method': 'failed'}
    
    def _yolo_detect_objects(self, image_data):
        """YOLO Í∞ùÏ≤¥ Ïù∏Ïãù"""
        try:
            if not PIL_AVAILABLE:
                return []
            
            # Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Ï†ÑÏ≤òÎ¶¨
            image = Image.open(io.BytesIO(image_data))
            
            # RGBA ‚Üí RGB Î≥ÄÌôò
            if image.mode in ['RGBA', 'LA']:
                rgb_image = Image.new('RGB', image.size, (255, 255, 255))
                rgb_image.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = rgb_image
            elif image.mode != 'RGB':
                image = image.convert('RGB')
            
            image_np = np.array(image)
            
            # YOLO Ï∂îÎ°†
            results = self.ai_models.yolo_model(image_np, conf=0.2)
            
            detections = []
            if len(results) > 0 and results[0].boxes is not None:
                boxes = results[0].boxes
                for i in range(len(boxes)):
                    conf = float(boxes.conf[i].cpu().numpy())
                    cls = int(boxes.cls[i].cpu().numpy())
                    class_name = self.ai_models.yolo_model.names[cls]
                    
                    detections.append({
                        'class': class_name,
                        'confidence': conf,
                        'class_id': cls
                    })
            
            return detections
            
        except Exception as e:
            print(f"[‚ùóYOLO Ï≤òÎ¶¨ Ïò§Î•ò] {str(e)}")
            return []
    
    def _extract_text_with_ocr(self, attachment_data, filename):
        """OCR ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú"""
        try:
            if not PIL_AVAILABLE:
                return {'text': '', 'success': False, 'error': 'PIL not available'}
            
            image = Image.open(io.BytesIO(attachment_data))
            
            # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
            if image.mode in ['RGBA', 'LA']:
                rgb_image = Image.new('RGB', image.size, (255, 255, 255))
                rgb_image.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = rgb_image
            elif image.mode != 'RGB':
                image = image.convert('RGB')
            
            image_np = np.array(image)
            
            # OCR ÏàòÌñâ
            result = self.ai_models.ocr_reader.readtext(image_np, paragraph=True)
            
            text = ""
            for detection in result:
                if len(detection) >= 3:
                    text_content = detection[1]
                    confidence = detection[2]
                    if confidence > 0.5:
                        text += text_content + " "
            
            return {
                'text': text.strip(),
                'success': bool(text.strip()),
                'method': 'ocr'
            }
            
        except Exception as e:
            print(f"[‚ùóOCR Ïò§Î•ò] {str(e)}")
            return {'text': '', 'success': False, 'error': str(e)}
    
    def _process_pdf(self, attachment_data, filename):
        """PDF Ï≤òÎ¶¨"""
        if not PDFPLUMBER_AVAILABLE and not PYPDF2_AVAILABLE:
            return {'type': 'document_pdf', 'error': 'PDF libraries not available', 'extraction_success': False}
        
        try:
            # pdfplumberÎ°ú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú ÏãúÎèÑ
            if PDFPLUMBER_AVAILABLE:
                with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
                    temp_file.write(attachment_data)
                    temp_file_path = temp_file.name
                
                try:
                    with pdfplumber.open(temp_file_path) as pdf:
                        text = ""
                        for page_num, page in enumerate(pdf.pages):
                            page_text = page.extract_text()
                            if page_text:
                                text += f"\n=== ÌéòÏù¥ÏßÄ {page_num + 1} ===\n{page_text}\n"
                    
                    if text.strip():
                        result = {
                            'type': 'document_pdf',
                            'extracted_text': text.strip(),
                            'extraction_success': True,
                            'extraction_method': 'pdfplumber',
                            'pages': len(pdf.pages)
                        }
                        
                        # Î¨∏ÏÑú ÏöîÏïΩ ÏÉùÏÑ±
                        result['document_summary'] = self._summarize_document(
                            text, filename, 'PDF Î≥¥Í≥†ÏÑú'
                        )
                        
                        return result
                        
                except Exception as e:
                    print(f"[‚ö†Ô∏è pdfplumber Ïã§Ìå®] {str(e)}")
                finally:
                    try:
                        os.unlink(temp_file_path)
                    except:
                        pass
            
            # PyPDF2Î°ú Ïû¨ÏãúÎèÑ
            if PYPDF2_AVAILABLE:
                return self._process_pdf_fallback(attachment_data, filename)
            
            return {'type': 'document_pdf', 'extraction_success': False, 'error': 'No PDF library available'}
            
        except Exception as e:
            print(f"[‚ùóPDF Ï≤òÎ¶¨ Ïò§Î•ò] {str(e)}")
            return {'type': 'document_pdf', 'error': str(e), 'extraction_success': False}
    
    def _process_pdf_fallback(self, attachment_data, filename):
        """PDF ÎåÄÏ≤¥ Ï≤òÎ¶¨ (PyPDF2)"""
        try:
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
                temp_file.write(attachment_data)
                temp_file_path = temp_file.name
            
            with open(temp_file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page_num, page in enumerate(pdf_reader.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== ÌéòÏù¥ÏßÄ {page_num + 1} ===\n{page_text}\n"
            
            if text.strip():
                result = {
                    'type': 'document_pdf',
                    'extracted_text': text.strip(),
                    'extraction_success': True,
                    'extraction_method': 'pypdf2',
                    'pages': len(pdf_reader.pages)
                }
                
                result['document_summary'] = self._summarize_document(
                    text, filename, 'PDF Î≥¥Í≥†ÏÑú'
                )
                
                return result
            
            return {'type': 'document_pdf', 'extraction_success': False}
            
        except Exception as e:
            return {'type': 'document_pdf', 'error': str(e), 'extraction_success': False}
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _process_docx(self, attachment_data, filename):
        """Word Î¨∏ÏÑú Ï≤òÎ¶¨"""
        if not DOCX_AVAILABLE:
            return {'type': 'document_word', 'error': 'python-docx not available', 'extraction_success': False}
        
        try:
            with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as temp_file:
                temp_file.write(attachment_data)
                temp_file_path = temp_file.name
            
            doc = Document(temp_file_path)
            
            text = ""
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text += paragraph.text + "\n"
            
            # Ìëú ÎÇ¥Ïö©ÎèÑ Ï∂îÏ∂ú
            for table in doc.tables:
                text += "\n=== Ìëú Îç∞Ïù¥ÌÑ∞ ===\n"
                for row in table.rows:
                    row_text = []
                    for cell in row.cells:
                        if cell.text.strip():
                            row_text.append(cell.text.strip())
                    if row_text:
                        text += " | ".join(row_text) + "\n"
            
            if text.strip():
                result = {
                    'type': 'document_word',
                    'extracted_text': text.strip(),
                    'extraction_success': True,
                    'paragraphs': len(doc.paragraphs),
                    'tables': len(doc.tables)
                }
                
                result['document_summary'] = self._summarize_document(
                    text, filename, 'Word Î¨∏ÏÑú'
                )
                
                return result
            
            return {'type': 'document_word', 'extraction_success': False}
            
        except Exception as e:
            return {'type': 'document_word', 'error': str(e), 'extraction_success': False}
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _process_pptx(self, attachment_data, filename):
        """PowerPoint Ï≤òÎ¶¨"""
        if not PPTX_AVAILABLE:
            return {'type': 'document_presentation', 'error': 'python-pptx not available', 'extraction_success': False}
        
        try:
            with tempfile.NamedTemporaryFile(suffix='.pptx', delete=False) as temp_file:
                temp_file.write(attachment_data)
                temp_file_path = temp_file.name
            
            prs = Presentation(temp_file_path)
            
            text = ""
            for slide_num, slide in enumerate(prs.slides):
                text += f"\n=== Ïä¨ÎùºÏù¥Îìú {slide_num + 1} ===\n"
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        text += shape.text + "\n"
                    
                    if hasattr(shape, 'has_table') and shape.has_table:
                        text += "\n--- Ìëú ---\n"
                        table = shape.table
                        for row in table.rows:
                            row_text = []
                            for cell in row.cells:
                                if cell.text.strip():
                                    row_text.append(cell.text.strip())
                            if row_text:
                                text += " | ".join(row_text) + "\n"
            
            if text.strip():
                result = {
                    'type': 'document_presentation',
                    'extracted_text': text.strip(),
                    'extraction_success': True,
                    'slides': len(prs.slides)
                }
                
                result['document_summary'] = self._summarize_document(
                    text, filename, 'PowerPoint ÌîÑÎ†àÏ††ÌÖåÏù¥ÏÖò'
                )
                
                return result
            
            return {'type': 'document_presentation', 'extraction_success': False}
            
        except Exception as e:
            return {'type': 'document_presentation', 'error': str(e), 'extraction_success': False}
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _process_xlsx(self, attachment_data, filename):
        """Excel Ï≤òÎ¶¨"""
        if not PANDAS_AVAILABLE:
            return {'type': 'document_spreadsheet', 'error': 'pandas not available', 'extraction_success': False}
        
        try:
            with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as temp_file:
                temp_file.write(attachment_data)
                temp_file_path = temp_file.name
            
            xl_file = pd.ExcelFile(temp_file_path)
            
            text = ""
            total_rows = 0
            
            for sheet_name in xl_file.sheet_names:
                df = pd.read_excel(temp_file_path, sheet_name=sheet_name)
                
                if not df.empty:
                    text += f"\n=== ÏãúÌä∏: {sheet_name} ===\n"
                    text += "Ïª¨Îüº: " + " | ".join(str(col) for col in df.columns) + "\n\n"
                    
                    for idx, row in df.head(20).iterrows():
                        row_text = []
                        for value in row:
                            if pd.notna(value):
                                row_text.append(str(value))
                            else:
                                row_text.append("")
                        text += " | ".join(row_text) + "\n"
                    
                    total_rows += len(df)
                    
                    if len(df) > 20:
                        text += f"... (Ï¥ù {len(df)}Ìñâ Ï§ë Ï≤òÏùå 20ÌñâÎßå ÌëúÏãú)\n"
            
            if text.strip():
                result = {
                    'type': 'document_spreadsheet',
                    'extracted_text': text.strip(),
                    'extraction_success': True,
                    'sheets': len(xl_file.sheet_names),
                    'total_rows': total_rows
                }
                
                result['document_summary'] = self._summarize_document(
                    text, filename, 'Excel Ïä§ÌîÑÎ†àÎìúÏãúÌä∏'
                )
                
                return result
            
            return {'type': 'document_spreadsheet', 'extraction_success': False}
            
        except Exception as e:
            return {'type': 'document_spreadsheet', 'error': str(e), 'extraction_success': False}
        finally:
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    def _summarize_document(self, text, filename, file_type):
        """Î¨∏ÏÑú ÏöîÏïΩ ÏÉùÏÑ±"""
        try:
            if len(text) > 4000:
                text = text[:4000] + "..."
            
            if not self.config.HF_TOKEN:
                return text[:300] + "..." if len(text) > 300 else text
            
            try:
                client = self.ai_models.get_inference_client()
                
                prompt = f"""Îã§ÏùåÏùÄ '{filename}' ÌååÏùºÏùò ÎÇ¥Ïö©ÏûÖÎãàÎã§. Ïù¥ Î¨∏ÏÑúÎ•º ÏöîÏïΩÌï¥Ï£ºÏÑ∏Ïöî.

ÌååÏùº ÌòïÏãù: {file_type}
ÎÇ¥Ïö©:
{text}

ÏöîÏïΩ ÏßÄÏπ®:
1. Ï£ºÏöî ÎÇ¥Ïö©ÏùÑ 3-5Í∞ú Ìè¨Ïù∏Ìä∏Î°ú ÏöîÏïΩ
2. ÌïµÏã¨ ÌÇ§ÏõåÎìúÏôÄ ÏàòÏπò Ìè¨Ìï®
3. 150Ïûê Ïù¥ÎÇ¥Î°ú Í∞ÑÍ≤∞ÌïòÍ≤å
4. ÌïúÍµ≠Ïñ¥Î°ú ÏùëÎãµ

ÏöîÏïΩ:"""
                
                messages = [
                    {"role": "system", "content": "ÎãπÏã†ÏùÄ Î¨∏ÏÑú ÏöîÏïΩ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."},
                    {"role": "user", "content": prompt}
                ]
                
                response = client.chat_completion(
                    messages=messages,
                    max_tokens=200,
                    temperature=0.3
                )
                
                return response.choices[0].message.content.strip()
                
            except Exception:
                # Í∞ÑÎã®Ìïú ÏöîÏïΩÏúºÎ°ú fallback
                sentences = text.split('.')
                important_sentences = [s.strip() for s in sentences[:3] if len(s.strip()) > 10]
                return '. '.join(important_sentences) + '.' if important_sentences else text[:200] + "..."
                
        except Exception as e:
            return text[:200] + "..." if len(text) > 200 else text
    
    def _manage_cache_size(self):
        """Ï∫êÏãú ÌÅ¨Í∏∞ Í¥ÄÎ¶¨"""
        if len(self.attachment_cache) > self.config.MAX_CACHE_SIZE:
            oldest_key = next(iter(self.attachment_cache))
            del self.attachment_cache[oldest_key]
            print(f"[üóëÔ∏è Ï∫êÏãú Ï†ïÎ¶¨] Ïò§ÎûòÎêú Ìï≠Î™© ÏÇ≠Ï†ú: {oldest_key}")
    
    def generate_attachment_summary(self, attachments):
        """Ï≤®Î∂ÄÌååÏùº ÏöîÏïΩ ÏÉùÏÑ±"""
        if not attachments:
            return ""
        
        total_files = len(attachments)
        
        # ÌååÏùº ÌÉÄÏûÖÎ≥Ñ Î∂ÑÎ•ò
        images = [att for att in attachments if att.get('type') == 'image']
        documents = [att for att in attachments if att.get('type', '').startswith('document_')]
        others = [att for att in attachments if att.get('type') not in ['image'] and not att.get('type', '').startswith('document_')]
        
        summary_parts = []
        
        if images:
            total_objects = sum(att.get('object_count', 0) for att in images)
            ocr_texts = [att for att in images if att.get('ocr_success')]
            
            if total_objects > 0:
                summary_parts.append(f"Ïù¥ÎØ∏ÏßÄ {len(images)}Í∞ú({total_objects}Í∞ú Í∞ùÏ≤¥)")
            else:
                summary_parts.append(f"Ïù¥ÎØ∏ÏßÄ {len(images)}Í∞ú")
                
            if ocr_texts:
                summary_parts.append(f"ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú {len(ocr_texts)}Í∞ú")
        
        if documents:
            doc_types = {}
            successful_extractions = 0
            
            for doc in documents:
                doc_type = doc.get('type', '').replace('document_', '')
                doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
                
                if doc.get('extraction_success'):
                    successful_extractions += 1
            
            for doc_type, count in doc_types.items():
                type_names = {
                    'pdf': 'PDF', 
                    'word': 'Word', 
                    'presentation': 'PPT', 
                    'spreadsheet': 'Excel'
                }
                type_name = type_names.get(doc_type, doc_type.upper())
                summary_parts.append(f"{type_name} {count}Í∞ú")
            
            if successful_extractions > 0:
                summary_parts.append(f"ÏöîÏïΩ Í∞ÄÎä• {successful_extractions}Í∞ú")
        
        if others:
            summary_parts.append(f"Í∏∞ÌÉÄ {len(others)}Í∞ú")
        
        if summary_parts:
            return f"üìé {total_files}Í∞ú ÌååÏùº: " + ", ".join(summary_parts)
        else:
            return f"üìé {total_files}Í∞ú ÌååÏùº"
    
    def clear_cache(self):
        """Ï∫êÏãú Ï¥àÍ∏∞Ìôî"""
        cache_count = len(self.attachment_cache)
        self.attachment_cache.clear()
        return cache_count
    
    def get_available_features(self):
        """ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Í∏∞Îä• Î™©Î°ù Î∞òÌôò"""
        return self.features