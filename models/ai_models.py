import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from ultralytics import YOLO
import easyocr
from huggingface_hub import InferenceClient
from nomic import embed, login
import os

class AIModels:
    def __init__(self, config):
        self.config = config
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
        self.yolo_model = None
        self.qwen_model = None
        self.qwen_tokenizer = None
        self.ocr_reader = None
        self.summarizer = None
        
        # Nomic ë¡œê·¸ì¸
        login(token=config.NOMIC_TOKEN)
        print("[âœ… Nomic ë¡œê·¸ì¸ ì™„ë£Œ]")
    
    def load_yolo_model(self):
        """YOLO ëª¨ë¸ ë¡œë”©"""
        if self.yolo_model is None:
            try:
                print("[ğŸ¤– YOLOv8 ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.yolo_model = YOLO(self.config.YOLO_MODEL)
                print("[âœ… YOLOv8 ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
                return True
            except Exception as e:
                print(f"[â—YOLO ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
                return False
        return True
    
    def load_qwen_model(self):
        """Qwen ëª¨ë¸ ë¡œë”©"""
        if self.qwen_model is None:
            print("[ğŸ¤– Qwen ëª¨ë¸ ë¡œë”© ì‹œì‘]")
            try:
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                
                self.qwen_tokenizer = AutoTokenizer.from_pretrained(
                    self.config.QWEN_MODEL, 
                    trust_remote_code=True
                )
                self.qwen_model = AutoModelForCausalLM.from_pretrained(
                    self.config.QWEN_MODEL,
                    device_map="auto",
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    trust_remote_code=True
                )
                self.qwen_model.eval()
                print("[âœ… Qwen ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
                return True
            except Exception as e:
                print(f"[â—Qwen ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
                return False
        return True
    
    def load_ocr_model(self):
        """OCR ëª¨ë¸ ë¡œë”©"""
        if self.ocr_reader is None:
            try:
                print("[ğŸ“– EasyOCR ëª¨ë¸ ë¡œë”© ì‹œì‘]")
                self.ocr_reader = easyocr.Reader(['ko', 'en'])
                print("[âœ… EasyOCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
                return True
            except Exception as e:
                print(f"[â—EasyOCR ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
                return False
        return True
    
    def load_summarizer(self):
        """ìš”ì•½ ëª¨ë¸ ë¡œë”©"""
        if self.summarizer is None:
            try:
                self.summarizer = pipeline(
                    "summarization", 
                    model="facebook/bart-large-cnn", 
                    tokenizer="facebook/bart-large-cnn"
                )
                print("[âœ… ìš”ì•½ ëª¨ë¸ ë¡œë”© ì™„ë£Œ]")
                return True
            except Exception as e:
                print(f"[â—ìš”ì•½ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨] {str(e)}")
                return False
        return True
    
    def get_inference_client(self):
        """HuggingFace Inference Client ìƒì„±"""
        return InferenceClient(
            model=self.config.HUGGINGFACE_MODEL,
            token=self.config.HF_TOKEN
        )
    
    def classify_email(self, text):
        """ì´ë©”ì¼ ë¶„ë¥˜"""
        try:
            text_inputs = [text] + self.config.CANDIDATE_LABELS
            result = embed.text(text_inputs, model='nomic-embed-text-v1', task_type='classification')
            
            embedding_list = result['embeddings']
            email_embedding = [embedding_list[0]]
            label_embeddings = embedding_list[1:]
            
            from sklearn.metrics.pairwise import cosine_similarity
            scores = cosine_similarity(email_embedding, label_embeddings)[0]
            best_index = scores.argmax()
            
            return {
                'classification': self.config.CANDIDATE_LABELS[best_index],
                'confidence': scores[best_index]
            }
            
        except Exception as e:
            print(f"[âš ï¸ ë¶„ë¥˜ ì‹¤íŒ¨] {str(e)}")
            return {'classification': 'unknown', 'confidence': 0.0}